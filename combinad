=== ./combinad ===
=== ./requirements.txt ===
# Core dependencies
google-adk==1.0.0
fastapi==0.115.0
uvicorn[standard]>=0.34.0
pydantic==2.9.2
pydantic-settings==2.6.0

# Database
asyncpg==0.29.0

# ADK DatabaseSessionService dependencies
sqlalchemy>=2.0.0
psycopg2-binary>=2.9.0

# Missing dependency for google-adk
deprecated>=1.2.14

# Microsoft Graph for Azure AD integration
msgraph-sdk>=1.0.0
azure-identity>=1.12.0

# Utilities
python-dotenv==1.0.1
requests==2.32.3

# Optional: For production logging
structlog==24.4.0
=== ./.dockerignore ===
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
ENV/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Testing
.pytest_cache/
.coverage
htmlcov/
.tox/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# Environment
.env
.env.local

# Git
.git/
.gitignore

# Documentation
docs/
*.md

# Docker
Dockerfile
.dockerignore
docker-compose.yml

# CI/CD
.github/
.gitlab-ci.yml
=== ./migrations/003_azure_ad_group_mappings.sql ===
-- Migration: Create Azure AD Group Mappings Table
-- Date: 2025-01-04
-- Description: Store Azure AD group to agent area_type mappings with weights for priority routing

-- Create table for Azure AD group mappings
CREATE TABLE IF NOT EXISTS azure_ad_group_mappings (
    mapping_id SERIAL PRIMARY KEY,
    group_name VARCHAR(255) NOT NULL UNIQUE,  -- Azure AD group display name
    area_type VARCHAR(50) NOT NULL,           -- Maps to agents.area_type
    weight INTEGER NOT NULL DEFAULT 0,        -- Higher weight = higher priority
    description TEXT,                         -- Optional description
    enabled BOOLEAN DEFAULT TRUE,             -- Enable/disable mapping without deleting
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Create index for fast lookups
CREATE INDEX IF NOT EXISTS idx_group_mappings_group_name ON azure_ad_group_mappings(group_name);
CREATE INDEX IF NOT EXISTS idx_group_mappings_area_type ON azure_ad_group_mappings(area_type);
CREATE INDEX IF NOT EXISTS idx_group_mappings_enabled ON azure_ad_group_mappings(enabled);
CREATE INDEX IF NOT EXISTS idx_group_mappings_weight ON azure_ad_group_mappings(weight DESC);

-- Insert default group mappings with weights
-- Higher weight = higher priority when user is in multiple groups
INSERT INTO azure_ad_group_mappings (group_name, area_type, weight, description) VALUES
    -- Admin has highest priority
    ('Admin-Users', 'admin', 1000, 'Administrators with full access'),

    -- Specialized departments with high priority
    ('Legal-Users', 'legal', 900, 'Legal department users'),
    ('Finance-Users', 'finance', 900, 'Finance department users'),
    ('HR-Users', 'hr', 850, 'Human Resources department users'),

    -- Technical teams
    ('Developer-Users', 'developer', 800, 'Software developers and engineers'),
    ('Operations-Users', 'operations', 800, 'Operations and DevOps teams'),
    ('Data-Analysis-Users', 'data_analysis', 750, 'Data analysts and scientists'),

    -- Business teams
    ('Sales-Users', 'sales', 700, 'Sales team members'),
    ('Marketing-Users', 'marketing', 700, 'Marketing department users'),
    ('Customer-Support-Users', 'customer_support', 650, 'Customer support agents'),

    -- General/fallback with lowest priority
    ('All-Employees', 'general', 100, 'All company employees - fallback agent')
ON CONFLICT (group_name) DO NOTHING;

-- Create trigger to update updated_at timestamp
CREATE OR REPLACE FUNCTION update_azure_ad_group_mappings_updated_at()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER azure_ad_group_mappings_updated_at
    BEFORE UPDATE ON azure_ad_group_mappings
    FOR EACH ROW
    EXECUTE FUNCTION update_azure_ad_group_mappings_updated_at();

-- Grant permissions (adjust as needed for your database user)
-- GRANT SELECT, INSERT, UPDATE, DELETE ON azure_ad_group_mappings TO your_app_user;
-- GRANT USAGE, SELECT ON SEQUENCE azure_ad_group_mappings_mapping_id_seq TO your_app_user;

COMMENT ON TABLE azure_ad_group_mappings IS 'Maps Azure AD security groups to agent area types with priority weights';
COMMENT ON COLUMN azure_ad_group_mappings.group_name IS 'Azure AD group display name (must match exactly)';
COMMENT ON COLUMN azure_ad_group_mappings.area_type IS 'Agent area_type to route to (matches agents.area_type)';
COMMENT ON COLUMN azure_ad_group_mappings.weight IS 'Priority weight - higher values take precedence for multi-group users';
COMMENT ON COLUMN azure_ad_group_mappings.enabled IS 'Whether this mapping is active';
=== ./migrations/002_remove_area_type_constraint.sql ===
-- Migration: Remove area_type CHECK constraint to allow dynamic Azure AD group mapping
-- Date: 2025-01-04
-- Description: Allows area_type to match any Azure AD group name, not restricted to predefined values

-- Step 1: Drop the existing CHECK constraint
-- Note: In PostgreSQL, we need to find and drop the constraint by name
-- The constraint name is usually auto-generated, so we'll recreate the table definition

-- First, let's drop the constraint if it exists
DO $$
BEGIN
    -- Try to drop the constraint if it exists
    ALTER TABLE agents DROP CONSTRAINT IF EXISTS agents_area_type_check;
EXCEPTION
    WHEN undefined_object THEN
        NULL;
END $$;

-- Step 2: Verify the change
-- You can now insert agents with any area_type value that matches your Azure AD groups
-- Example: area_type = 'Legal-Users', 'HR-Users', 'Engineering-Team', etc.

-- Step 3: Update index (optional but recommended)
-- Add index for better query performance when filtering by area_type
CREATE INDEX IF NOT EXISTS idx_agents_area_type ON agents(area_type);

-- Migration completed successfully
-- area_type can now be any string value matching your Azure AD group structure
=== ./TEAMS_INTEGRATION.md ===
# Microsoft Teams Integration with Azure AD Group Routing

## Overview

This integration enables automatic routing of Microsoft Teams messages to appropriate GCP agents based on users' Azure AD group membership.

**Key Features:**
- ✅ **Database-Driven Configuration**: Group mappings stored in PostgreSQL, no code changes needed
- ✅ **Weight-Based Priority**: Flexible priority system for users in multiple groups
- ✅ **REST API Management**: Full CRUD operations for managing group mappings
- ✅ **Session Persistence**: Conversation memory across Teams interactions
- ✅ **Fallback Support**: Automatic routing to general agent when no match found

## How It Works

```
Teams User Message
    ↓
Microsoft Graph API (get user's AD groups)
    ↓
Azure AD Group Mapper (maps groups to area_type)
    ↓
Agent Router (finds agent with matching area_type)
    ↓
GCP Agent Service (invokes agent with conversation memory)
    ↓
Response to Teams User
```

## Architecture

### 1. Database Schema

The `area_type` column in the `agents` table now accepts any string value (constraint removed):

```sql
area_type VARCHAR(50) DEFAULT 'general'  -- No CHECK constraint
```

This allows `area_type` to match your Azure AD group names dynamically.

### 2. Group to Agent Mapping (Database-Driven)

Group mappings are now stored in the database table `azure_ad_group_mappings` with configurable weights:

```sql
CREATE TABLE azure_ad_group_mappings (
    mapping_id SERIAL PRIMARY KEY,
    group_name VARCHAR(255) NOT NULL UNIQUE,  -- Azure AD group display name
    area_type VARCHAR(50) NOT NULL,           -- Agent area_type to route to
    weight INTEGER NOT NULL DEFAULT 0,        -- Higher weight = higher priority
    description TEXT,
    enabled BOOLEAN DEFAULT TRUE
);
```

**Default Mappings with Weights:**
- Admin-Users → admin (weight: 1000)
- Legal-Users → legal (weight: 900)
- Finance-Users → finance (weight: 900)
- HR-Users → hr (weight: 850)
- Developer-Users → developer (weight: 800)
- And more...

**Weight-Based Routing:**
When a user belongs to multiple Azure AD groups, the system uses the mapping with the **highest weight** to determine which agent to route to.

### 3. Agent Creation Examples

Create agents with `area_type` matching your groups:

```sql
-- Legal agent for Legal-Users group
INSERT INTO agents (agent_id, name, area_type, instruction, description, model_name)
VALUES (
    'agent-legal-001',
    'legal_assistant',
    'legal',  -- Matches GROUP_TO_AREA_MAP['Legal-Users']
    'You are a legal assistant specializing in contract law and compliance.',
    'Legal department AI assistant',
    'gemini-2.0-flash'
);

-- HR agent for HR-Users group
INSERT INTO agents (agent_id, name, area_type, instruction, description, model_name)
VALUES (
    'agent-hr-001',
    'hr_assistant',
    'hr',  -- Matches GROUP_TO_AREA_MAP['HR-Users']
    'You are an HR assistant helping with employee policies and benefits.',
    'Human Resources AI assistant',
    'gemini-2.0-flash'
);

-- General fallback agent
INSERT INTO agents (agent_id, name, area_type, instruction, description, model_name)
VALUES (
    'agent-general-001',
    'general_assistant',
    'general',  -- Default fallback
    'You are a general-purpose assistant.',
    'General AI assistant',
    'gemini-2.0-flash'
);
```

## Setup Instructions

### Step 1: Apply Database Migrations

```bash
# Run migration to remove area_type constraint
psql -h $DB_HOST -U $DB_USER -d $DB_NAME -f migrations/002_remove_area_type_constraint.sql

# Run migration to create group mappings table
psql -h $DB_HOST -U $DB_USER -d $DB_NAME -f migrations/003_azure_ad_group_mappings.sql
```

This will create the `azure_ad_group_mappings` table with default mappings pre-populated.

### Step 2: Configure Environment Variables

Add to your `.env` file:

```bash
# Microsoft Graph API credentials
GRAPH_TENANT_ID=your-azure-tenant-id
GRAPH_CLIENT_ID=your-teams-app-client-id
GRAPH_CLIENT_SECRET=your-app-secret
```

### Step 3: Create Agents with Matching area_type

Ensure you have agents in the database with `area_type` values that match your Azure AD groups.

### Step 4: Deploy to Cloud Run

```bash
# Commit changes
git add -A
git commit -m "Add Teams integration with Azure AD group routing"
git push

# Deploy will happen automatically via Cloud Build
```

## API Endpoints

### 1. Process Teams Message

**Endpoint:** `POST /api/v1/teams/message`

Routes a message to the appropriate agent based on user's Azure AD groups.

```bash
curl -X POST https://your-service.run.app/api/v1/teams/message \
  -H "Content-Type: application/json" \
  -d '{
    "user_message": "I need help with a contract review",
    "aad_user_id": "12345-67890-abcdef",
    "user_name": "John Doe",
    "session_id": "teams-session-123",
    "persist_session": true
  }'
```

**Response:**
```json
{
  "success": true,
  "response": "I'd be happy to help with your contract review...",
  "agent_name": "legal_assistant",
  "agent_area": "legal",
  "user_groups": ["Legal-Users", "All-Employees"],
  "session_id": "teams-session-123"
}
```

### 2. Get User's Agent Info

**Endpoint:** `GET /api/v1/teams/user/{aad_user_id}/agents`

Shows which agent(s) a user can access.

```bash
curl https://your-service.run.app/api/v1/teams/user/12345-67890-abcdef/agents
```

**Response:**
```json
{
  "user_groups": ["Legal-Users", "All-Employees"],
  "primary_agent": {
    "name": "legal_assistant",
    "description": "Legal department AI assistant",
    "area": "legal"
  },
  "accessible_agents": [
    {
      "name": "legal_assistant",
      "description": "Legal department AI assistant",
      "area": "legal"
    },
    {
      "name": "general_assistant",
      "description": "General AI assistant",
      "area": "general"
    }
  ]
}
```

### 3. Health Check

**Endpoint:** `GET /api/v1/teams/health`

```bash
curl https://your-service.run.app/api/v1/teams/health
```

### 4. Manage Group Mappings

#### List All Group Mappings

**Endpoint:** `GET /api/v1/groups/mappings`

```bash
curl https://your-service.run.app/api/v1/groups/mappings
```

#### Create New Mapping

**Endpoint:** `POST /api/v1/groups/mappings`

```bash
curl -X POST https://your-service.run.app/api/v1/groups/mappings \
  -H "Content-Type: application/json" \
  -d '{
    "group_name": "Engineering-Team",
    "area_type": "developer",
    "weight": 800,
    "description": "Engineering team members",
    "enabled": true
  }'
```

#### Update Existing Mapping

**Endpoint:** `PUT /api/v1/groups/mappings/{mapping_id}`

```bash
curl -X PUT https://your-service.run.app/api/v1/groups/mappings/5 \
  -H "Content-Type: application/json" \
  -d '{
    "weight": 950,
    "description": "Updated description"
  }'
```

#### Delete Mapping

**Endpoint:** `DELETE /api/v1/groups/mappings/{mapping_id}`

```bash
curl -X DELETE https://your-service.run.app/api/v1/groups/mappings/5
```

#### Get Mapping by Group Name

**Endpoint:** `GET /api/v1/groups/mappings/by-group/{group_name}`

```bash
curl https://your-service.run.app/api/v1/groups/mappings/by-group/Legal-Users
```

## Routing Logic

### Weight-Based Priority

If a user belongs to multiple groups, the router uses **weight-based selection**:

1. Query database for all group mappings matching user's groups
2. Sort mappings by weight (descending)
3. Select the mapping with the **highest weight**
4. Route to the agent with matching `area_type`

**Default Weights:**
- Admin-Users: **1000** (highest priority)
- Legal-Users: **900**
- Finance-Users: **900**
- HR-Users: **850**
- Developer-Users: **800**
- Operations-Users: **800**
- Data-Analysis-Users: **750**
- Sales-Users: **700**
- Marketing-Users: **700**
- Customer-Support-Users: **650**
- All-Employees: **100** (lowest priority)

### Fallback Behavior

- If no matching agent found for user's group → uses 'general' agent
- If no groups found for user → uses 'general' agent
- If 'general' agent doesn't exist → returns error

## Integration with Microsoft Teams Bot

### Teams Bot Implementation

Your Microsoft Teams bot (Azure Bot Service) should call this API:

```python
# In your Teams bot handler
async def on_message_activity(self, turn_context: TurnContext):
    # Get user info from Teams
    user_message = turn_context.activity.text
    aad_user_id = turn_context.activity.from_property.aad_object_id
    user_name = turn_context.activity.from_property.name
    conversation_id = turn_context.activity.conversation.id

    # Call your GCP API
    response = await call_teams_api(
        user_message=user_message,
        aad_user_id=aad_user_id,
        user_name=user_name,
        session_id=f"teams-{conversation_id}"
    )

    # Send response back to Teams
    await turn_context.send_activity(response['response'])
```

### Example Azure Bot Service Integration

```python
import aiohttp

async def call_teams_api(user_message, aad_user_id, user_name, session_id):
    """Call GCP Teams integration API."""

    async with aiohttp.ClientSession() as session:
        async with session.post(
            'https://your-service.run.app/api/v1/teams/message',
            json={
                'user_message': user_message,
                'aad_user_id': aad_user_id,
                'user_name': user_name,
                'session_id': session_id,
                'persist_session': True
            }
        ) as resp:
            return await resp.json()
```

## Testing

### 1. Test Group Mapping

```bash
# List all group mappings
curl http://localhost:8080/api/v1/groups/mappings

# Get specific group mapping
curl http://localhost:8080/api/v1/groups/mappings/by-group/Legal-Users
```

### 2. Test API Locally

```bash
# Start the service
python -m src.main

# Test the Teams endpoint
curl -X POST http://localhost:8080/api/v1/teams/message \
  -H "Content-Type: application/json" \
  -d '{
    "user_message": "Help me with a legal question",
    "aad_user_id": "test-user-123",
    "user_name": "Test User",
    "session_id": "test-session-1"
  }'
```

### 3. Test with Real Azure AD

Requires:
- Azure AD tenant configured
- App registration with Microsoft Graph permissions
- Users assigned to security groups

## Customization

### Add Custom Group Mappings

Use the API to add new group mappings:

```bash
curl -X POST http://localhost:8080/api/v1/groups/mappings \
  -H "Content-Type: application/json" \
  -d '{
    "group_name": "Engineering-Team",
    "area_type": "developer",
    "weight": 850,
    "description": "Software engineering team",
    "enabled": true
  }'
```

Or directly via SQL:

```sql
INSERT INTO azure_ad_group_mappings (group_name, area_type, weight, description)
VALUES ('Engineering-Team', 'developer', 850, 'Software engineering team');
```

### Change Priority Order

Update weights via API to change priority:

```bash
# Make Engineering-Team higher priority than Legal-Users
curl -X PUT http://localhost:8080/api/v1/groups/mappings/5 \
  -H "Content-Type: application/json" \
  -d '{"weight": 950}'
```

Or via SQL:

```sql
-- Higher weight = higher priority
UPDATE azure_ad_group_mappings
SET weight = 950
WHERE group_name = 'Engineering-Team';
```

### Multi-Agent Access

Users in multiple groups can access multiple agents:

```python
# Get all agents user can access
accessible_agents = await agent_router.get_available_agents_for_user(user_groups)
```

## Monitoring

### Logs to Monitor

```bash
# View routing decisions
gcloud run services logs read $SERVICE_NAME --region $REGION | grep "Routing user"

# View group mappings
gcloud run services logs read $SERVICE_NAME --region $REGION | grep "area_type"

# View errors
gcloud run services logs read $SERVICE_NAME --region $REGION | grep "ERROR"
```

### Key Metrics

- **Route Success Rate**: Percentage of messages successfully routed
- **Agent Distribution**: Which agents are being used most
- **Group Coverage**: Percentage of users with matching agents

## Troubleshooting

### Issue: User gets "No suitable agent found"

**Solution:** Create an agent with matching `area_type` or ensure 'general' agent exists.

### Issue: Microsoft Graph API errors

**Solution:** Check Graph API permissions and credentials:
- User.Read
- Directory.Read.All
- GroupMember.Read.All

### Issue: Wrong agent selected

**Solution:**
1. Check group mappings: `GET /api/v1/groups/mappings`
2. Verify user's groups are mapped correctly
3. Check weight values - higher weight = higher priority
4. Update weights if needed: `PUT /api/v1/groups/mappings/{id}`

## Security Considerations

1. **API Authentication**: Add authentication to Teams API endpoints
2. **Rate Limiting**: Implement rate limiting for production
3. **Input Validation**: Validate all user inputs
4. **Audit Logging**: Log all routing decisions for compliance

## Next Steps

1. ✅ Database migration applied
2. ✅ Environment variables configured
3. ✅ Agents created with matching area_types
4. ⬜ Azure Bot Service configured to call this API
5. ⬜ Teams app deployed to organization
6. ⬜ Users assigned to appropriate Azure AD groups
7. ⬜ Testing completed

---

**Questions?** Check the main README or open an issue.
=== ./Dockerfile ===
# Use Python 3.11 slim image
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    GOOGLE_GENAI_USE_VERTEXAI=TRUE

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app

USER appuser

# Expose port (Cloud Run will inject PORT env var)
EXPOSE 8080

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8080/health')"

# Run the application
CMD ["python", "-m", "src.main"]
=== ./.env.example ===
# Application Configuration
PORT=8080
HOST=0.0.0.0
ENVIRONMENT=development

# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=agents_db
DB_USER=postgres
DB_PASSWORD=postgres

# Google Cloud Configuration
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_CLOUD_REGION=us-central1
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account-key.json

# ADK Vertex AI Configuration
# CRITICAL: These environment variables MUST be set for ADK to work with Vertex AI
# ADK reads these during initialization to configure the GenAI client
GOOGLE_GENAI_USE_VERTEXAI=TRUE
# GOOGLE_CLOUD_PROJECT is typically set by Cloud Run automatically
# GOOGLE_CLOUD_LOCATION defaults to us-central1 if not set

# Microsoft Teams / Azure AD Integration (Optional)
# Required only if integrating with Microsoft Teams bot
GRAPH_TENANT_ID=your-azure-tenant-id
GRAPH_CLIENT_ID=your-app-client-id
GRAPH_CLIENT_SECRET=your-app-secret

# Session Management
# Set to 'true' to enable persistent database-backed conversation sessions using ADK's DatabaseSessionService
# ADK will automatically create its own session tables in your PostgreSQL database
# When false, sessions are ephemeral (in-memory only, destroyed after request)
PERSIST_SESSIONS=false

# Optional: Logging
LOG_LEVEL=INFO
=== ./ARCHITECTURE.md ===
# Architecture Documentation

## Overview

This project implements a **Ports & Adapters (Hexagonal) Architecture** with **Dependency Injection** to build a maintainable, testable, and scalable ADK (Agent Development Kit) service.

## Architectural Patterns

### 1. Ports & Adapters (Hexagonal Architecture)

The application is structured in three main layers:

#### Domain Layer (Core/Hexagon)
- **Location**: `src/domain/`
- **Purpose**: Contains business logic, domain models, and port interfaces
- **Dependencies**: None (depends on nothing)
- **Components**:
  - `models/`: Domain entities (AgentConfig, ToolConfig, ModelConfig)
  - `ports/`: Interface definitions (AgentRepository)
  - `services/`: Business logic (AgentService)

#### Infrastructure Layer (Adapters)
- **Location**: `src/infrastructure/`
- **Purpose**: Implements ports with concrete technologies
- **Dependencies**: Domain layer
- **Components**:
  - `adapters/postgres/`: PostgreSQL implementation of AgentRepository
  - `tools/`: Tool registry and implementations

#### Application Layer
- **Location**: `src/application/`
- **Purpose**: Orchestrates the application, handles HTTP, DI
- **Dependencies**: Domain and Infrastructure layers
- **Components**:
  - `api/`: FastAPI routes and endpoints
  - `di/`: Dependency injection container

### 2. Dependency Injection

**Pattern**: Constructor Injection with Container

```python
# Port (interface)
class AgentRepository(ABC):
    @abstractmethod
    async def get_agent_by_id(self, agent_id: str): ...

# Adapter (implementation)
class PostgresAgentRepository(AgentRepository):
    async def get_agent_by_id(self, agent_id: str): ...

# Service (depends on port, not adapter)
class AgentService:
    def __init__(self, repository: AgentRepository):
        self.repository = repository  # Injected dependency

# Container (wires everything together)
class Container:
    async def get_agent_service(self) -> AgentService:
        repository = await self.init_repository()
        return AgentService(repository)
```

**Benefits**:
- Easy to test (inject mocks)
- Loose coupling
- Easy to swap implementations

### 3. Repository Pattern

**Purpose**: Abstract data access behind an interface

```python
# Domain defines what it needs (port)
class AgentRepository(ABC):
    @abstractmethod
    async def get_agent_by_id(self, agent_id: str): ...

# Infrastructure provides it (adapter)
class PostgresAgentRepository(AgentRepository):
    async def get_agent_by_id(self, agent_id: str):
        # PostgreSQL-specific implementation
        ...
```

**Benefits**:
- Domain doesn't know about PostgreSQL
- Easy to add other adapters (MongoDB, Redis, etc.)
- Testable with in-memory implementations

### 4. Registry Pattern

**Purpose**: Manage dynamic tool loading and registration

```python
class ToolRegistry:
    def __init__(self):
        self._tools: dict[str, Callable] = {}

    def register_tool(self, name: str, func: Callable):
        self._tools[name] = func

    def get_tool(self, config: ToolConfig):
        return self._tools.get(config.function_name)
```

**Benefits**:
- Dynamic tool loading
- Centralized tool management
- Easy to extend with new tools

## Data Flow

### Request Flow (Invoke Agent)

```
1. HTTP Request
   ↓
2. FastAPI Route (application/api/routes.py)
   ↓
3. Get Container
   ↓
4. Get Agent Service (via DI)
   ↓
5. Agent Service → Repository (port)
   ↓
6. PostgreSQL Adapter (implements port)
   ↓
7. Database Query
   ↓
8. AgentConfig returned
   ↓
9. Agent Service → Tool Registry
   ↓
10. Tool Registry returns tool functions
    ↓
11. Create ADK Agent with config + tools
    ↓
12. Invoke Agent with prompt
    ↓
13. Return Response
```

### Dependency Graph

```
main.py
  └─→ Container (DI)
       ├─→ AgentRepository (port)
       │    └─→ PostgresAgentRepository (adapter)
       │         └─→ asyncpg (database driver)
       │
       ├─→ ToolRegistry
       │    └─→ sample_tools (functions)
       │
       └─→ AgentService
            ├─→ AgentRepository (injected)
            └─→ ToolRegistry (injected)
```

## Design Principles

### SOLID Principles

#### Single Responsibility Principle (SRP)
- Each class has one reason to change
- `AgentService`: Manages agents
- `PostgresAgentRepository`: Handles database operations
- `ToolRegistry`: Manages tools

#### Open/Closed Principle (OCP)
- Open for extension, closed for modification
- Add new adapters without changing domain code
- Add new tools without changing ToolRegistry core

#### Liskov Substitution Principle (LSP)
- Subtypes must be substitutable for base types
- Any `AgentRepository` implementation can replace another
- `PostgresAgentRepository` can be swapped with `MongoAgentRepository`

#### Interface Segregation Principle (ISP)
- Clients shouldn't depend on interfaces they don't use
- `AgentRepository` only defines methods needed by `AgentService`

#### Dependency Inversion Principle (DIP)
- Depend on abstractions, not concretions
- `AgentService` depends on `AgentRepository` (interface)
- Not on `PostgresAgentRepository` (concrete class)

### Other Design Principles

#### Domain-Driven Design (DDD)
- Domain models represent business concepts
- Rich domain models with validation
- Domain services for business logic

#### Separation of Concerns
- HTTP concerns in API layer
- Business logic in domain layer
- Data access in infrastructure layer

#### Fail Fast
- Validate at domain model creation
- Use immutable domain objects (frozen dataclasses)
- Type hints for compile-time checks

## Testing Strategy

### Unit Tests

```python
# Test domain service with mock repository
def test_agent_service():
    mock_repo = Mock(spec=AgentRepository)
    mock_repo.get_agent_by_id.return_value = mock_config

    service = AgentService(mock_repo, mock_registry)
    agent = await service.get_agent("agent-001")

    assert agent is not None
    mock_repo.get_agent_by_id.assert_called_once()
```

### Integration Tests

```python
# Test with real PostgreSQL
@pytest.fixture
async def postgres_repo():
    repo = await PostgresAgentRepository.create(...)
    yield repo
    await repo.close()

async def test_postgres_repository(postgres_repo):
    agent = await postgres_repo.get_agent_by_id("agent-001")
    assert agent.name == "search_assistant"
```

### End-to-End Tests

```python
# Test complete flow
async def test_invoke_agent_endpoint(client):
    response = await client.post("/api/v1/invoke", json={
        "agent_id": "agent-001",
        "prompt": "Hello"
    })
    assert response.status_code == 200
```

## Extension Points

### Adding a New Adapter

To add a new repository adapter (e.g., MongoDB):

1. **Create adapter**:
```python
class MongoAgentRepository(AgentRepository):
    async def get_agent_by_id(self, agent_id: str):
        # MongoDB implementation
        ...
```

2. **Update container**:
```python
class Container:
    async def init_repository(self):
        if os.getenv("REPO_TYPE") == "mongo":
            return await MongoAgentRepository.create(...)
        return await PostgresAgentRepository.create(...)
```

### Adding a New Tool

1. **Create tool function**:
```python
def my_tool(param: str) -> dict:
    """Tool description."""
    return {"status": "success", "result": param}
```

2. **Add to database**:
```sql
INSERT INTO tools (tool_id, tool_name, tool_type, function_name)
VALUES ('tool-xyz', 'my_tool', 'function', 'my_tool');
```

3. **Tool registry auto-discovers it**

### Adding a New Endpoint

1. **Add route**:
```python
@router.post("/api/v1/custom")
async def custom_endpoint():
    service = await get_container().get_agent_service()
    # Use service...
```

## Cloud Run Considerations

### Stateless Design
- No local state (except caching)
- All configuration in database
- Container can scale horizontally

### Connection Pooling
- AsyncPG connection pool
- Shared across requests
- Configured in Container

### Graceful Shutdown
- FastAPI lifespan events
- Close database connections on shutdown

### Health Checks
- `/health` endpoint
- Kubernetes-style readiness

## Security Considerations

### Credentials Management
- Environment variables for config
- Secrets for sensitive data (passwords)
- Google Cloud Secret Manager integration

### Database Security
- Parameterized queries (SQL injection protection)
- Connection encryption (SSL/TLS)
- Least privilege database user

### API Security
- CORS configuration
- Rate limiting (add middleware)
- Authentication (add auth middleware)

## Performance Considerations

### Caching
- Agent cache in `AgentService`
- Avoid recreating agents on every request
- Cache invalidation via reload endpoint

### Connection Pooling
- AsyncPG pool (min=10, max=20)
- Reuse connections across requests

### Async/Await
- Non-blocking I/O
- FastAPI async endpoints
- AsyncPG for database

## Monitoring & Observability

### Logging
- Structured logging
- Log levels (INFO, ERROR)
- Request/response logging

### Metrics (to add)
- Request count
- Response time
- Database query time
- Agent invocation count

### Tracing (to add)
- OpenTelemetry
- Trace requests across services

## Future Enhancements

1. **Caching Layer**: Add Redis for agent caching
2. **Event Sourcing**: Track agent configuration changes
3. **Multi-tenancy**: Support multiple organizations
4. **Authentication**: Add OAuth2/JWT
5. **Rate Limiting**: Prevent abuse
6. **Metrics**: Prometheus/Cloud Monitoring
7. **A/B Testing**: Support multiple agent versions
8. **Versioning**: Version agent configurations

## References

- [Hexagonal Architecture](https://alistair.cockburn.us/hexagonal-architecture/)
- [Dependency Injection](https://en.wikipedia.org/wiki/Dependency_injection)
- [Repository Pattern](https://martinfowler.com/eaaCatalog/repository.html)
- [Domain-Driven Design](https://martinfowler.com/bliki/DomainDrivenDesign.html)
- [SOLID Principles](https://en.wikipedia.org/wiki/SOLID)
=== ./README.md ===
# ADK Agent Service with PostgreSQL Configuration

A production-ready Cloud Run application using Google's Agent Development Kit (ADK) with PostgreSQL-based configuration management. Built with ports & adapters (hexagonal) architecture and dependency injection for maintainability and testability.

## Features

- **Google ADK Integration**: Build and deploy AI agents using Google's latest Agent Development Kit
- **PostgreSQL Configuration**: Store agent configurations, tools, and models in PostgreSQL
- **Ports & Adapters Architecture**: Clean separation between domain logic and infrastructure
- **Dependency Injection**: Modular, testable design with clean dependency management
- **Dynamic Tool Loading**: Load and register tools from configuration
- **Multi-Agent Support**: Support for hierarchical agent systems with sub-agents
- **Cloud Run Ready**: Optimized for Google Cloud Run deployment
- **RESTful API**: FastAPI-based REST endpoints for agent interaction

## Architecture

```
src/
├── domain/                 # Core business logic (ports)
│   ├── models/            # Domain models
│   │   └── agent_config.py
│   ├── ports/             # Repository interfaces
│   │   └── agent_repository.py
│   └── services/          # Business services
│       └── agent_service.py
├── infrastructure/        # Adapters
│   ├── adapters/
│   │   └── postgres/      # PostgreSQL adapter
│   │       ├── postgres_agent_repository.py
│   │       └── schema.sql
│   └── tools/             # ADK tool implementations
│       ├── sample_tools.py
│       └── tool_registry.py
├── application/           # Application layer
│   ├── api/               # API endpoints
│   │   └── routes.py
│   └── di/                # Dependency injection
│       └── container.py
└── main.py                # Entry point
```

## Prerequisites

- Python 3.11+
- PostgreSQL 14+
- Docker (for containerized deployment)
- Google Cloud account (for Cloud Run deployment)
- Google Cloud SDK (`gcloud` CLI)

## Installation

### Local Development

1. **Clone the repository**

```bash
git clone <repository-url>
cd testtesttest
```

2. **Create virtual environment**

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Set up environment variables**

```bash
cp .env.example .env
# Edit .env with your configuration
```

5. **Set up PostgreSQL database**

```bash
# Create database
createdb agents_db

# Run schema
psql agents_db < src/infrastructure/adapters/postgres/schema.sql
```

6. **Run the application**

```bash
python -m src.main
```

### Docker Development

1. **Start services with Docker Compose**

```bash
docker-compose up -d
```

This will start:
- PostgreSQL database on port 5432
- Agent service on port 8080

2. **View logs**

```bash
docker-compose logs -f agent-service
```

3. **Stop services**

```bash
docker-compose down
```

## Usage

### API Endpoints

#### Health Check

```bash
curl http://localhost:8080/health
```

#### List Agents

```bash
curl http://localhost:8080/api/v1/agents
```

#### Get Agent Details

```bash
curl http://localhost:8080/api/v1/agents/agent-001
```

#### Invoke Agent by ID

```bash
curl -X POST http://localhost:8080/api/v1/invoke \
  -H "Content-Type: application/json" \
  -d '{
    "agent_id": "agent-001",
    "prompt": "What is the weather in San Francisco?"
  }'
```

#### Invoke Agent by Name

```bash
curl -X POST http://localhost:8080/api/v1/invoke \
  -H "Content-Type: application/json" \
  -d '{
    "agent_name": "search_assistant",
    "prompt": "Search for information about AI agents"
  }'
```

#### Reload Agent Configuration

```bash
curl -X POST http://localhost:8080/api/v1/agents/agent-001/reload
```

### Interactive API Documentation

Visit http://localhost:8080/docs for Swagger UI documentation.

## Database Schema

The application uses the following tables:

- **agents**: Stores agent configurations (name, instruction, model, etc.)
- **tools**: Stores tool definitions
- **agent_tools**: Many-to-many relationship between agents and tools
- **agent_sub_agents**: Hierarchical relationships between agents

See `src/infrastructure/adapters/postgres/schema.sql` for the complete schema.

## Adding Custom Tools

1. **Create a tool function** in `src/infrastructure/tools/sample_tools.py`:

```python
def my_custom_tool(param: str) -> dict:
    """
    Description of what the tool does.

    Args:
        param: Parameter description

    Returns:
        A dictionary with the result
    """
    return {
        "status": "success",
        "result": f"Processed: {param}"
    }
```

2. **Add tool to database**:

```sql
INSERT INTO tools (tool_id, tool_name, tool_type, function_name, description)
VALUES ('tool-004', 'my_custom_tool', 'function', 'my_custom_tool', 'My custom tool');

-- Associate with an agent
INSERT INTO agent_tools (agent_id, tool_id)
VALUES ('agent-001', 'tool-004');
```

3. **Reload the agent** to pick up the new tool.

## Cloud Run Deployment

### Prerequisites

```bash
# Set your project ID
export PROJECT_ID=your-project-id
export REGION=us-central1
export SERVICE_NAME=adk-agent-service

# Authenticate
gcloud auth login
gcloud config set project $PROJECT_ID
```

### Deploy to Cloud Run

```bash
# Build and push container
gcloud builds submit --tag gcr.io/$PROJECT_ID/$SERVICE_NAME

# Deploy to Cloud Run
gcloud run deploy $SERVICE_NAME \
  --image gcr.io/$PROJECT_ID/$SERVICE_NAME \
  --platform managed \
  --region $REGION \
  --allow-unauthenticated \
  --set-env-vars "DB_HOST=your-postgres-host" \
  --set-env-vars "DB_NAME=agents_db" \
  --set-env-vars "DB_USER=postgres" \
  --set-secrets "DB_PASSWORD=db-password-secret:latest" \
  --set-secrets "GOOGLE_APPLICATION_CREDENTIALS=/secrets/gcp-credentials" \
  --memory 1Gi \
  --cpu 1 \
  --max-instances 10
```

### Using Cloud SQL

For production, use Cloud SQL for PostgreSQL:

```bash
# Create Cloud SQL instance
gcloud sql instances create agents-db \
  --database-version=POSTGRES_16 \
  --tier=db-f1-micro \
  --region=$REGION

# Create database
gcloud sql databases create agents_db --instance=agents-db

# Deploy with Cloud SQL connection
gcloud run deploy $SERVICE_NAME \
  --image gcr.io/$PROJECT_ID/$SERVICE_NAME \
  --add-cloudsql-instances $PROJECT_ID:$REGION:agents-db \
  --set-env-vars "DB_HOST=/cloudsql/$PROJECT_ID:$REGION:agents-db" \
  ...
```

## Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `PORT` | Server port | 8080 |
| `HOST` | Server host | 0.0.0.0 |
| `ENVIRONMENT` | Environment (development/production) | development |
| `DB_HOST` | PostgreSQL host | localhost |
| `DB_PORT` | PostgreSQL port | 5432 |
| `DB_NAME` | Database name | agents_db |
| `DB_USER` | Database user | postgres |
| `DB_PASSWORD` | Database password | postgres |
| `GOOGLE_CLOUD_PROJECT` | GCP project ID | - |
| `GOOGLE_APPLICATION_CREDENTIALS` | Path to GCP credentials | - |

## Development

### Project Structure

- **Domain Layer**: Contains business logic and defines interfaces (ports)
- **Infrastructure Layer**: Implements ports with concrete adapters (PostgreSQL, tools)
- **Application Layer**: Handles HTTP requests, dependency injection

### Design Principles

1. **Ports & Adapters**: Domain logic is independent of infrastructure
2. **Dependency Injection**: Dependencies are injected via the container
3. **Separation of Concerns**: Each layer has a specific responsibility
4. **SOLID Principles**: Single responsibility, Open/closed, etc.

### Testing

```bash
# Install test dependencies
pip install pytest pytest-asyncio pytest-cov

# Run tests
pytest

# Run with coverage
pytest --cov=src tests/
```

## Troubleshooting

### Connection Issues

- Ensure PostgreSQL is running and accessible
- Check environment variables are set correctly
- Verify network connectivity

### Agent Not Found

- Check if agent exists in database
- Verify agent is enabled
- Try reloading agent configuration

### Tool Errors

- Ensure tool function exists in tool registry
- Check tool is enabled in database
- Verify tool parameters are correct

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## License

MIT License

## Resources

- [Google ADK Documentation](https://google.github.io/adk-docs/)
- [Google Cloud Run Documentation](https://cloud.google.com/run/docs)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Ports & Adapters Architecture](https://alistair.cockburn.us/hexagonal-architecture/)
=== ./docker-compose.yml ===
version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: agents_db
    environment:
      POSTGRES_DB: agents_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./src/infrastructure/adapters/postgres/schema.sql:/docker-entrypoint-initdb.d/schema.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Agent Service
  agent-service:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: agent_service
    ports:
      - "8080:8080"
    environment:
      PORT: 8080
      HOST: 0.0.0.0
      ENVIRONMENT: development
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: agents_db
      DB_USER: postgres
      DB_PASSWORD: postgres
      GOOGLE_CLOUD_PROJECT: ${GOOGLE_CLOUD_PROJECT}
      GOOGLE_APPLICATION_CREDENTIALS: /app/credentials.json
    volumes:
      - ./credentials.json:/app/credentials.json:ro
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped

volumes:
  postgres_data:
=== ./scripts/cloud_sql_setup.sh ===
#!/bin/bash

# Cloud SQL setup script

set -e

# Configuration
PROJECT_ID=${GOOGLE_CLOUD_PROJECT:-"your-project-id"}
REGION=${REGION:-"us-central1"}
INSTANCE_NAME=${INSTANCE_NAME:-"agents-db"}
DB_NAME=${DB_NAME:-"agents_db"}
ROOT_PASSWORD=${ROOT_PASSWORD:-"$(openssl rand -base64 32)"}

echo "======================================"
echo "Setting up Cloud SQL PostgreSQL"
echo "======================================"
echo "Project: $PROJECT_ID"
echo "Region: $REGION"
echo "Instance: $INSTANCE_NAME"
echo "Database: $DB_NAME"
echo "======================================"

# Check if gcloud is installed
if ! command -v gcloud &> /dev/null; then
    echo "Error: gcloud CLI is not installed"
    exit 1
fi

# Set project
gcloud config set project $PROJECT_ID

# Enable Cloud SQL API
echo "Enabling Cloud SQL API..."
gcloud services enable sqladmin.googleapis.com

# Create Cloud SQL instance
echo "Creating Cloud SQL instance (this may take several minutes)..."
gcloud sql instances create $INSTANCE_NAME \
    --database-version=POSTGRES_16 \
    --tier=db-f1-micro \
    --region=$REGION \
    --root-password="$ROOT_PASSWORD" \
    --storage-type=SSD \
    --storage-size=10GB \
    --storage-auto-increase \
    --backup-start-time=03:00 \
    --database-flags=max_connections=100

# Create database
echo "Creating database..."
gcloud sql databases create $DB_NAME --instance=$INSTANCE_NAME

# Get connection name
CONNECTION_NAME=$(gcloud sql instances describe $INSTANCE_NAME \
    --format='value(connectionName)')

echo "======================================"
echo "Cloud SQL setup complete!"
echo "======================================"
echo ""
echo "Connection details:"
echo "  Instance: $INSTANCE_NAME"
echo "  Connection Name: $CONNECTION_NAME"
echo "  Database: $DB_NAME"
echo "  Root Password: $ROOT_PASSWORD"
echo ""
echo "Save the root password securely!"
echo ""
echo "Next steps:"
echo "1. Create application database user:"
echo "   gcloud sql users create app_user --instance=$INSTANCE_NAME --password=YOUR_PASSWORD"
echo ""
echo "2. Run schema using Cloud SQL Proxy:"
echo "   cloud_sql_proxy -instances=$CONNECTION_NAME=tcp:5432 &"
echo "   PGPASSWORD=YOUR_PASSWORD psql -h localhost -U app_user -d $DB_NAME -f src/infrastructure/adapters/postgres/schema.sql"
echo ""
echo "3. Update Cloud Run service with connection:"
echo "   gcloud run services update YOUR_SERVICE \\"
echo "     --add-cloudsql-instances $CONNECTION_NAME \\"
echo "     --update-env-vars DB_HOST=/cloudsql/$CONNECTION_NAME"
echo ""
=== ./scripts/deploy.sh ===
#!/bin/bash

# Deployment script for Cloud Run

set -e

# Configuration
PROJECT_ID=${GOOGLE_CLOUD_PROJECT:-"your-project-id"}
REGION=${REGION:-"us-central1"}
SERVICE_NAME=${SERVICE_NAME:-"adk-agent-service"}
IMAGE_NAME="gcr.io/$PROJECT_ID/$SERVICE_NAME"

echo "======================================"
echo "Deploying ADK Agent Service"
echo "======================================"
echo "Project: $PROJECT_ID"
echo "Region: $REGION"
echo "Service: $SERVICE_NAME"
echo "======================================"

# Check if gcloud is installed
if ! command -v gcloud &> /dev/null; then
    echo "Error: gcloud CLI is not installed"
    exit 1
fi

# Check if authenticated
if ! gcloud auth list --filter=status:ACTIVE --format="value(account)" &> /dev/null; then
    echo "Error: Not authenticated with gcloud. Run: gcloud auth login"
    exit 1
fi

# Set project
echo "Setting project to $PROJECT_ID..."
gcloud config set project $PROJECT_ID

# Enable required APIs
echo "Enabling required APIs..."
gcloud services enable \
    cloudbuild.googleapis.com \
    run.googleapis.com \
    containerregistry.googleapis.com \
    sqladmin.googleapis.com

# Build container
echo "Building container image..."
gcloud builds submit --tag $IMAGE_NAME

# Deploy to Cloud Run
echo "Deploying to Cloud Run..."
gcloud run deploy $SERVICE_NAME \
    --image $IMAGE_NAME \
    --platform managed \
    --region $REGION \
    --allow-unauthenticated \
    --memory 1Gi \
    --cpu 1 \
    --max-instances 10 \
    --timeout 300 \
    --set-env-vars "ENVIRONMENT=production"

# Get service URL
SERVICE_URL=$(gcloud run services describe $SERVICE_NAME \
    --platform managed \
    --region $REGION \
    --format 'value(status.url)')

echo "======================================"
echo "Deployment complete!"
echo "Service URL: $SERVICE_URL"
echo "======================================"
echo ""
echo "Next steps:"
echo "1. Set up Cloud SQL and configure DB_* environment variables"
echo "2. Configure secrets for sensitive data"
echo "3. Test the service: curl $SERVICE_URL/health"
echo ""
=== ./scripts/setup_db.sh ===
#!/bin/bash

# Database setup script

set -e

# Configuration
DB_HOST=${DB_HOST:-"localhost"}
DB_PORT=${DB_PORT:-"5432"}
DB_NAME=${DB_NAME:-"agents_db"}
DB_USER=${DB_USER:-"postgres"}
DB_PASSWORD=${DB_PASSWORD:-"postgres"}

echo "======================================"
echo "Setting up PostgreSQL Database"
echo "======================================"
echo "Host: $DB_HOST"
echo "Port: $DB_PORT"
echo "Database: $DB_NAME"
echo "User: $DB_USER"
echo "======================================"

# Check if psql is installed
if ! command -v psql &> /dev/null; then
    echo "Error: psql is not installed"
    exit 1
fi

# Create database if it doesn't exist
echo "Creating database if it doesn't exist..."
PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -p $DB_PORT -U $DB_USER -tc "SELECT 1 FROM pg_database WHERE datname = '$DB_NAME'" | grep -q 1 || \
    PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -p $DB_PORT -U $DB_USER -c "CREATE DATABASE $DB_NAME"

# Run schema
echo "Running schema..."
PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -f src/infrastructure/adapters/postgres/schema.sql

echo "======================================"
echo "Database setup complete!"
echo "======================================"
echo ""
echo "Sample data has been loaded:"
echo "- 2 agents (search_assistant, data_analyst)"
echo "- 3 tools (web_search, calculate, get_weather)"
echo ""
echo "You can now start the application."
echo ""
=== ./src/domain/models/agent_config.py ===
"""Domain models for agent configuration."""

from dataclasses import dataclass, field
from typing import Any, Optional
from enum import Enum


class ModelType(str, Enum):
    """Supported model types."""
    GEMINI_2_5_FLASH = "gemini-2.5-flash"
    GEMINI_2_5_PRO = "gemini-2.5-pro"
    GEMINI_2_0_FLASH = "gemini-2.0-flash"
    GEMINI_1_5_PRO = "gemini-1.5-pro"
    GEMINI_1_5_FLASH = "gemini-1.5-flash"


class AgentType(str, Enum):
    """Agent types."""
    ASSISTANT = "assistant"
    COORDINATOR = "coordinator"
    SPECIALIST = "specialist"
    RAG = "rag"
    TOOL = "tool"


class AreaType(str, Enum):
    """
    Agent area/domain types.

    Note: area_type is now flexible and can match any Azure AD group name.
    These are common examples, but not restricted to this list.
    """
    GENERAL = "general"
    MARKETING = "marketing"
    LEGAL = "legal"
    DEVELOPER = "developer"
    OPERATIONS = "operations"
    SALES = "sales"
    CUSTOMER_SUPPORT = "customer_support"
    FINANCE = "finance"
    HR = "hr"
    DATA_ANALYSIS = "data_analysis"


class VectorDBType(str, Enum):
    """Supported vector database types."""
    VERTEX_RAG = "vertex_rag"
    QDRANT = "qdrant"
    PINECONE = "pinecone"
    WEAVIATE = "weaviate"


@dataclass(frozen=True)
class ModelConfig:
    """Configuration for the AI model."""

    model_name: str
    temperature: float = 0.7
    max_tokens: Optional[int] = None
    top_p: Optional[float] = None
    top_k: Optional[int] = None

    def __post_init__(self):
        """Validate model configuration."""
        if not 0.0 <= self.temperature <= 2.0:
            raise ValueError("Temperature must be between 0.0 and 2.0")
        if self.max_tokens is not None and self.max_tokens <= 0:
            raise ValueError("max_tokens must be positive")


@dataclass(frozen=True)
class CorpusConfig:
    """Configuration for a RAG corpus."""

    corpus_id: str
    corpus_name: str
    display_name: str
    description: Optional[str] = None
    vertex_corpus_name: Optional[str] = None
    embedding_model: str = "text-embedding-005"
    vector_db_type: str = "vertex_rag"
    vector_db_config: dict[str, Any] = field(default_factory=dict)
    document_count: int = 0
    chunk_size: int = 1000
    chunk_overlap: int = 200
    priority: int = 1  # Priority when assigned to an agent
    metadata: dict[str, Any] = field(default_factory=dict)
    enabled: bool = True

    def __post_init__(self):
        """Validate corpus configuration."""
        if not self.corpus_name:
            raise ValueError("Corpus name cannot be empty")
        if self.chunk_size <= 0:
            raise ValueError("chunk_size must be positive")
        if self.chunk_overlap < 0:
            raise ValueError("chunk_overlap cannot be negative")


@dataclass(frozen=True)
class ToolConfig:
    """Configuration for an agent tool."""

    tool_id: str
    tool_name: str
    tool_type: str  # 'function', 'builtin', 'third_party', 'rag', 'agent'
    function_name: Optional[str] = None  # For function tools
    parameters: dict[str, Any] = field(default_factory=dict)
    description: Optional[str] = None
    enabled: bool = True

    def __post_init__(self):
        """Validate tool configuration."""
        valid_types = ['function', 'builtin', 'third_party', 'rag', 'agent']
        if self.tool_type not in valid_types:
            raise ValueError(f"tool_type must be one of {valid_types}")


@dataclass(frozen=True)
class AgentConfig:
    """Configuration for an AI agent."""

    agent_id: str
    name: str
    model: ModelConfig
    instruction: str
    description: str
    agent_type: str = "assistant"
    area_type: str = "general"
    tools: list[ToolConfig] = field(default_factory=list)
    corpuses: list[CorpusConfig] = field(default_factory=list)
    sub_agent_ids: list[str] = field(default_factory=list)
    enabled: bool = True
    metadata: dict[str, Any] = field(default_factory=dict)

    def __post_init__(self):
        """Validate agent configuration."""
        if not self.name:
            raise ValueError("Agent name cannot be empty")
        if not self.instruction:
            raise ValueError("Agent instruction cannot be empty")

        # Validate agent_type
        valid_agent_types = [t.value for t in AgentType]
        if self.agent_type not in valid_agent_types:
            raise ValueError(f"agent_type must be one of {valid_agent_types}")

        # Validate area_type
        valid_area_types = [t.value for t in AreaType]
        if self.area_type not in valid_area_types:
            raise ValueError(f"area_type must be one of {valid_area_types}")
=== ./src/domain/models/azure_ad_models.py ===
"""Domain models for Azure AD integration."""

from dataclasses import dataclass
from datetime import datetime
from typing import Optional


@dataclass(frozen=True)
class AzureADGroupMapping:
    """
    Azure AD group to agent area_type mapping.

    Attributes:
        mapping_id: Unique identifier
        group_name: Azure AD group display name
        area_type: Agent area_type to route to
        weight: Priority weight (higher = higher priority)
        description: Optional description
        enabled: Whether mapping is active
        created_at: Creation timestamp
        updated_at: Last update timestamp
    """
    mapping_id: int
    group_name: str
    area_type: str
    weight: int
    description: Optional[str] = None
    enabled: bool = True
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None
=== ./src/domain/models/session_models.py ===
"""Domain models for session and conversation history."""

from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Optional
from enum import Enum


class SessionStatus(str, Enum):
    """Session status types."""
    ACTIVE = "active"
    CLOSED = "closed"
    ARCHIVED = "archived"


class MessageRole(str, Enum):
    """Message role types."""
    USER = "user"
    AGENT = "agent"
    SYSTEM = "system"
    TOOL = "tool"


@dataclass(frozen=True)
class Message:
    """Represents a message in a conversation."""

    message_id: str
    session_id: str
    role: str
    content: str
    tool_name: Optional[str] = None
    tool_call_id: Optional[str] = None
    tokens_used: Optional[int] = None
    model_used: Optional[str] = None
    metadata: dict[str, Any] = field(default_factory=dict)
    created_at: Optional[datetime] = None

    def __post_init__(self):
        """Validate message."""
        valid_roles = [r.value for r in MessageRole]
        if self.role not in valid_roles:
            raise ValueError(f"role must be one of {valid_roles}")


@dataclass(frozen=True)
class Session:
    """Represents a conversation session."""

    session_id: str
    app_name: str
    user_id: str
    agent_id: Optional[str] = None
    title: Optional[str] = None
    status: str = "active"
    metadata: dict[str, Any] = field(default_factory=dict)
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None
    last_message_at: Optional[datetime] = None
    closed_at: Optional[datetime] = None

    def __post_init__(self):
        """Validate session."""
        valid_statuses = [s.value for s in SessionStatus]
        if self.status not in valid_statuses:
            raise ValueError(f"status must be one of {valid_statuses}")
=== ./src/domain/models/__init__.py ===
from .agent_config import (
    AgentConfig,
    ToolConfig,
    ModelConfig,
    CorpusConfig,
    AgentType,
    AreaType,
    VectorDBType,
)
from .session_models import (
    Session,
    Message,
    SessionStatus,
    MessageRole,
)

__all__ = [
    "AgentConfig",
    "ToolConfig",
    "ModelConfig",
    "CorpusConfig",
    "AgentType",
    "AreaType",
    "VectorDBType",
    "Session",
    "Message",
    "SessionStatus",
    "MessageRole",
]
=== ./src/domain/services/__init__.py ===
from .agent_service import AgentService

__all__ = ["AgentService"]
=== ./src/domain/services/agent_service.py ===
"""Agent service for creating and managing ADK agents."""

from typing import Optional, Any
from google.adk.agents import Agent, LlmAgent
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.genai import types

from src.domain.models import AgentConfig
from src.domain.ports import AgentRepository
from src.infrastructure.tools import ToolRegistry


class AgentService:
    """
    Service for creating and managing ADK agents.

    This service uses the repository (port) to load agent configurations
    and the tool registry to resolve tool functions, then creates
    Google ADK Agent instances.
    """

    def __init__(
        self,
        repository: AgentRepository,
        tool_registry: ToolRegistry,
        session_service: Optional[Any] = None
    ):
        """
        Initialize the agent service.

        Args:
            repository: The agent repository (port interface)
            tool_registry: The tool registry for resolving tools
            session_service: Optional session service (PostgreSQL or InMemory)
        """
        self.repository = repository
        self.tool_registry = tool_registry
        self._agent_cache: dict[str, Agent] = {}
        self.persistent_session_service = session_service  # For database sessions

    async def get_agent(self, agent_id: str, use_cache: bool = True) -> Optional[Agent]:
        """
        Get an ADK agent by ID.

        Args:
            agent_id: The unique identifier of the agent
            use_cache: If True, return cached agent if available

        Returns:
            Agent instance if found, None otherwise
        """
        if use_cache and agent_id in self._agent_cache:
            return self._agent_cache[agent_id]

        config = await self.repository.get_agent_by_id(agent_id)
        if not config:
            return None

        agent = await self._create_agent_from_config(config)
        if agent and use_cache:
            self._agent_cache[agent_id] = agent

        return agent

    async def get_agent_by_name(self, name: str, use_cache: bool = True) -> Optional[Agent]:
        """
        Get an ADK agent by name.

        Args:
            name: The name of the agent
            use_cache: If True, return cached agent if available

        Returns:
            Agent instance if found, None otherwise
        """
        config = await self.repository.get_agent_by_name(name)
        if not config:
            return None

        # Check cache by agent_id
        if use_cache and config.agent_id in self._agent_cache:
            return self._agent_cache[config.agent_id]

        agent = await self._create_agent_from_config(config)
        if agent and use_cache:
            self._agent_cache[config.agent_id] = agent

        return agent

    async def list_agents(self, enabled_only: bool = True) -> list[Agent]:
        """
        List all ADK agents.

        Args:
            enabled_only: If True, return only enabled agents

        Returns:
            List of Agent instances
        """
        configs = await self.repository.list_agents(enabled_only)
        agents = []

        for config in configs:
            agent = await self._create_agent_from_config(config)
            if agent:
                agents.append(agent)

        return agents

    async def _create_agent_from_config(self, config: AgentConfig) -> Optional[Agent]:
        """
        Create an ADK agent from configuration.

        Note: The model parameter accepts either a string (e.g., "gemini-2.0-flash")
        or a model wrapper object. We pass the model name string directly.

        Args:
            config: The agent configuration

        Returns:
            Agent instance or None if creation fails
        """
        if not config.enabled:
            return None

        try:
            # Get tools for the agent (pass corpuses and agent_service for RAG/agent tools)
            tools = self.tool_registry.get_tools_for_configs(
                config.tools,
                corpuses=config.corpuses,
                agent_service=self
            )

            # Get sub-agents if any
            sub_agents = []
            if config.sub_agent_ids:
                for sub_agent_id in config.sub_agent_ids:
                    sub_agent = await self.get_agent(sub_agent_id)
                    if sub_agent:
                        sub_agents.append(sub_agent)

            # Create agent based on whether it has sub-agents
            if sub_agents:
                # Use LlmAgent for hierarchical agents
                agent = LlmAgent(
                    name=config.name,
                    model=config.model.model_name,
                    description=config.description,
                    instruction=config.instruction,
                    tools=tools if tools else None,
                    sub_agents=sub_agents,
                )
            else:
                # Use simple Agent for leaf agents
                agent = Agent(
                    name=config.name,
                    model=config.model.model_name,
                    description=config.description,
                    instruction=config.instruction,
                    tools=tools if tools else None,
                )

            return agent

        except Exception as e:
            print(f"Error creating agent {config.name}: {e}")
            return None

    async def reload_agent(self, agent_id: str) -> Optional[Agent]:
        """
        Reload an agent from the database, bypassing cache.

        Args:
            agent_id: The unique identifier of the agent

        Returns:
            Agent instance if found, None otherwise
        """
        # Remove from cache if present
        if agent_id in self._agent_cache:
            del self._agent_cache[agent_id]

        return await self.get_agent(agent_id, use_cache=False)

    def clear_cache(self):
        """Clear the agent cache."""
        self._agent_cache.clear()

    async def invoke_agent(
        self, agent_id: str, prompt: str, **kwargs
    ) -> str:
        """
        Invoke an agent with a prompt.

        Args:
            agent_id: The unique identifier of the agent
            prompt: The prompt to send to the agent
            **kwargs: Additional arguments (user_id, session_id)

        Returns:
            The agent's response as a string
        """
        agent = await self.get_agent(agent_id)
        if not agent:
            raise ValueError(f"Agent {agent_id} not found")

        # Always use Runner for proper ADK invocation
        return await self._invoke_with_runner(agent_id, agent, prompt, **kwargs)

    async def _invoke_with_runner(
        self, agent_id: str, agent: Agent, prompt: str, **kwargs
    ) -> str:
        """
        Invoke agent using Runner (proper ADK way).

        Args:
            agent_id: The agent ID
            agent: The agent instance
            prompt: The prompt to send
            **kwargs: Additional arguments (user_id, session_id, persist_session)

        Returns:
            The agent's response as a string
        """
        import uuid

        # Extract user and session info
        user_id = kwargs.get("user_id", "default_user")
        session_id = kwargs.get("session_id")
        persist_session = kwargs.get("persist_session", False)

        # Generate unique session ID for each request if not provided
        if not session_id:
            session_id = f"sess_{uuid.uuid4().hex[:12]}"

        app_name = f"agent_{agent_id}"

        # Choose session service: persistent (database) or ephemeral (in-memory)
        if persist_session and self.persistent_session_service:
            session_service = self.persistent_session_service
        else:
            # Create ephemeral session service for this invocation only
            session_service = InMemorySessionService()

        # Create the session (InMemorySessionService and DatabaseSessionService don't accept agent_id)
        await session_service.create_session(
            app_name=app_name,
            user_id=user_id,
            session_id=session_id
        )

        # Create a fresh runner
        runner = Runner(
            agent=agent,
            app_name=app_name,
            session_service=session_service
        )

        # Create message content
        message = types.Content(
            role="user",
            parts=[types.Part(text=prompt)]
        )

        # Run agent and collect response
        response_text = ""
        try:
            async for event in runner.run_async(
                user_id=user_id,
                session_id=session_id,
                new_message=message
            ):
                # Collect all text from events
                if hasattr(event, 'content') and event.content:
                    if hasattr(event.content, 'parts'):
                        for part in event.content.parts:
                            if hasattr(part, 'text') and part.text:
                                response_text += part.text
        except Exception as e:
            raise RuntimeError(f"Error invoking agent: {str(e)}")

        # Note: ADK's DatabaseSessionService automatically persists all messages
        # No manual message saving needed

        return response_text if response_text else "No response generated"

    async def invoke_agent_by_name(
        self, name: str, prompt: str, **kwargs
    ) -> str:
        """
        Invoke an agent by name with a prompt.

        Args:
            name: The name of the agent
            prompt: The prompt to send to the agent
            **kwargs: Additional arguments (user_id, session_id, etc.)

        Returns:
            The agent's response as a string
        """
        # Get the agent config to find the agent_id
        config = await self.repository.get_agent_by_name(name)
        if not config:
            raise ValueError(f"Agent '{name}' not found")

        # Use invoke_agent with the agent_id
        return await self.invoke_agent(config.agent_id, prompt, **kwargs)
=== ./src/domain/ports/corpus_repository.py ===
"""Repository port (interface) for corpus management."""

from abc import ABC, abstractmethod
from typing import Optional
from src.domain.models import CorpusConfig


class CorpusRepository(ABC):
    """
    Port (interface) for corpus repository.

    This defines the contract that any adapter must implement
    to provide corpus management.
    """

    @abstractmethod
    async def get_corpus_by_id(self, corpus_id: str) -> Optional[CorpusConfig]:
        """
        Retrieve a corpus configuration by ID.

        Args:
            corpus_id: The unique identifier of the corpus

        Returns:
            CorpusConfig if found, None otherwise
        """
        pass

    @abstractmethod
    async def get_corpus_by_name(self, corpus_name: str) -> Optional[CorpusConfig]:
        """
        Retrieve a corpus configuration by name.

        Args:
            corpus_name: The name of the corpus

        Returns:
            CorpusConfig if found, None otherwise
        """
        pass

    @abstractmethod
    async def list_corpuses(self, enabled_only: bool = True) -> list[CorpusConfig]:
        """
        List all corpus configurations.

        Args:
            enabled_only: If True, return only enabled corpuses

        Returns:
            List of CorpusConfig objects
        """
        pass

    @abstractmethod
    async def get_corpuses_for_agent(self, agent_id: str) -> list[CorpusConfig]:
        """
        Get all corpuses assigned to a specific agent.

        Args:
            agent_id: The unique identifier of the agent

        Returns:
            List of CorpusConfig objects ordered by priority
        """
        pass

    @abstractmethod
    async def save_corpus(self, corpus: CorpusConfig) -> CorpusConfig:
        """
        Save or update a corpus configuration.

        Args:
            corpus: The corpus configuration to save

        Returns:
            The saved CorpusConfig
        """
        pass

    @abstractmethod
    async def delete_corpus(self, corpus_id: str) -> bool:
        """
        Delete a corpus configuration.

        Args:
            corpus_id: The unique identifier of the corpus

        Returns:
            True if deleted, False if not found
        """
        pass

    @abstractmethod
    async def assign_corpus_to_agent(
        self, agent_id: str, corpus_id: str, priority: int = 1
    ) -> bool:
        """
        Assign a corpus to an agent.

        Args:
            agent_id: The unique identifier of the agent
            corpus_id: The unique identifier of the corpus
            priority: Priority level (lower = higher priority)

        Returns:
            True if assigned successfully
        """
        pass

    @abstractmethod
    async def unassign_corpus_from_agent(
        self, agent_id: str, corpus_id: str
    ) -> bool:
        """
        Remove a corpus assignment from an agent.

        Args:
            agent_id: The unique identifier of the agent
            corpus_id: The unique identifier of the corpus

        Returns:
            True if unassigned successfully
        """
        pass
=== ./src/domain/ports/group_mapping_repository.py ===
"""Port interface for Azure AD group mapping repository."""

from abc import ABC, abstractmethod
from typing import List, Optional

from src.domain.models.azure_ad_models import AzureADGroupMapping


class GroupMappingRepository(ABC):
    """Repository interface for Azure AD group mappings."""

    @abstractmethod
    async def get_all_mappings(self, enabled_only: bool = True) -> List[AzureADGroupMapping]:
        """
        Get all group mappings.

        Args:
            enabled_only: Only return enabled mappings

        Returns:
            List of group mappings
        """
        pass

    @abstractmethod
    async def get_mapping_by_group_name(self, group_name: str) -> Optional[AzureADGroupMapping]:
        """
        Get mapping for specific group.

        Args:
            group_name: Azure AD group name

        Returns:
            Group mapping or None
        """
        pass

    @abstractmethod
    async def get_mappings_by_group_names(self, group_names: List[str]) -> List[AzureADGroupMapping]:
        """
        Get mappings for multiple groups.

        Args:
            group_names: List of Azure AD group names

        Returns:
            List of matching group mappings
        """
        pass

    @abstractmethod
    async def create_mapping(
        self,
        group_name: str,
        area_type: str,
        weight: int,
        description: Optional[str] = None,
        enabled: bool = True
    ) -> AzureADGroupMapping:
        """
        Create new group mapping.

        Args:
            group_name: Azure AD group name
            area_type: Agent area_type
            weight: Priority weight
            description: Optional description
            enabled: Whether enabled

        Returns:
            Created mapping
        """
        pass

    @abstractmethod
    async def update_mapping(
        self,
        mapping_id: int,
        area_type: Optional[str] = None,
        weight: Optional[int] = None,
        description: Optional[str] = None,
        enabled: Optional[bool] = None
    ) -> Optional[AzureADGroupMapping]:
        """
        Update existing mapping.

        Args:
            mapping_id: Mapping ID to update
            area_type: New area_type (optional)
            weight: New weight (optional)
            description: New description (optional)
            enabled: New enabled status (optional)

        Returns:
            Updated mapping or None
        """
        pass

    @abstractmethod
    async def delete_mapping(self, mapping_id: int) -> bool:
        """
        Delete mapping.

        Args:
            mapping_id: Mapping ID to delete

        Returns:
            True if deleted, False otherwise
        """
        pass
=== ./src/domain/ports/agent_repository.py ===
"""Repository port (interface) for agent configuration."""

from abc import ABC, abstractmethod
from typing import Optional
from src.domain.models import AgentConfig, ToolConfig


class AgentRepository(ABC):
    """
    Port (interface) for agent configuration repository.

    This defines the contract that any adapter (like PostgreSQL) must implement
    to provide agent configuration data.
    """

    @abstractmethod
    async def get_agent_by_id(self, agent_id: str) -> Optional[AgentConfig]:
        """
        Retrieve an agent configuration by ID.

        Args:
            agent_id: The unique identifier of the agent

        Returns:
            AgentConfig if found, None otherwise
        """
        pass

    @abstractmethod
    async def get_agent_by_name(self, name: str) -> Optional[AgentConfig]:
        """
        Retrieve an agent configuration by name.

        Args:
            name: The name of the agent

        Returns:
            AgentConfig if found, None otherwise
        """
        pass

    @abstractmethod
    async def list_agents(self, enabled_only: bool = True) -> list[AgentConfig]:
        """
        List all agent configurations.

        Args:
            enabled_only: If True, return only enabled agents

        Returns:
            List of AgentConfig objects
        """
        pass

    @abstractmethod
    async def get_tools_for_agent(self, agent_id: str) -> list[ToolConfig]:
        """
        Get all tools configured for a specific agent.

        Args:
            agent_id: The unique identifier of the agent

        Returns:
            List of ToolConfig objects
        """
        pass

    @abstractmethod
    async def get_tool_by_id(self, tool_id: str) -> Optional[ToolConfig]:
        """
        Retrieve a tool configuration by ID.

        Args:
            tool_id: The unique identifier of the tool

        Returns:
            ToolConfig if found, None otherwise
        """
        pass

    @abstractmethod
    async def save_agent(self, agent: AgentConfig) -> AgentConfig:
        """
        Save or update an agent configuration.

        Args:
            agent: The agent configuration to save

        Returns:
            The saved AgentConfig
        """
        pass

    @abstractmethod
    async def delete_agent(self, agent_id: str) -> bool:
        """
        Delete an agent configuration.

        Args:
            agent_id: The unique identifier of the agent

        Returns:
            True if deleted, False if not found
        """
        pass
=== ./src/domain/ports/__init__.py ===
from .agent_repository import AgentRepository
from .corpus_repository import CorpusRepository

__all__ = ["AgentRepository", "CorpusRepository"]
=== ./src/domain/__init__.py ===
=== ./src/application/di/container.py ===
"""Dependency injection container for the application."""

import os
import asyncpg
from typing import Optional

from google.adk.sessions import DatabaseSessionService, InMemorySessionService

from src.domain.ports import AgentRepository, CorpusRepository
from src.domain.ports.group_mapping_repository import GroupMappingRepository
from src.domain.services import AgentService
from src.infrastructure.adapters.postgres import PostgresAgentRepository, PostgresCorpusRepository
from src.infrastructure.adapters.postgres.postgres_group_mapping_repository import PostgresGroupMappingRepository
from src.infrastructure.tools import ToolRegistry


class Container:
    """
    Dependency injection container.

    This container manages the lifecycle of application dependencies
    and provides a clean way to inject them where needed.
    """

    def __init__(self):
        """Initialize the container."""
        self._repository: Optional[AgentRepository] = None
        self._corpus_repository: Optional[CorpusRepository] = None
        self._group_mapping_repository: Optional[GroupMappingRepository] = None
        self._tool_registry: Optional[ToolRegistry] = None
        self._agent_service: Optional[AgentService] = None
        self._session_service: Optional[any] = None

    async def init_repository(self) -> AgentRepository:
        """
        Initialize and return the agent repository.

        Returns:
            AgentRepository instance
        """
        if self._repository is None:
            # Get database configuration from environment variables
            db_host = os.getenv("DB_HOST", "localhost")
            db_port = int(os.getenv("DB_PORT", "5432"))
            db_name = os.getenv("DB_NAME", "agents_db")
            db_user = os.getenv("DB_USER", "postgres")
            db_password = os.getenv("DB_PASSWORD", "postgres")

            # Create PostgreSQL repository
            self._repository = await PostgresAgentRepository.create(
                host=db_host,
                port=db_port,
                database=db_name,
                user=db_user,
                password=db_password,
            )

        return self._repository

    async def init_corpus_repository(self) -> CorpusRepository:
        """
        Initialize and return the corpus repository.

        Uses the same database connection as the agent repository.

        Returns:
            CorpusRepository instance
        """
        if self._corpus_repository is None:
            # Get database configuration from environment variables
            db_host = os.getenv("DB_HOST", "localhost")
            db_port = int(os.getenv("DB_PORT", "5432"))
            db_name = os.getenv("DB_NAME", "agents_db")
            db_user = os.getenv("DB_USER", "postgres")
            db_password = os.getenv("DB_PASSWORD", "postgres")

            # For simplicity, create a new pool for corpus repository
            # In production, you might want to share the pool
            pool = await asyncpg.create_pool(
                host=db_host,
                port=db_port,
                database=db_name,
                user=db_user,
                password=db_password,
                min_size=5,
                max_size=10,
            )
            self._corpus_repository = PostgresCorpusRepository(pool)

        return self._corpus_repository

    async def init_group_mapping_repository(self) -> GroupMappingRepository:
        """
        Initialize and return the group mapping repository.

        Uses the same database connection as the agent repository.

        Returns:
            GroupMappingRepository instance
        """
        if self._group_mapping_repository is None:
            # Get database configuration from environment variables
            db_host = os.getenv("DB_HOST", "localhost")
            db_port = int(os.getenv("DB_PORT", "5432"))
            db_name = os.getenv("DB_NAME", "agents_db")
            db_user = os.getenv("DB_USER", "postgres")
            db_password = os.getenv("DB_PASSWORD", "postgres")

            # Create a pool for group mapping repository
            pool = await asyncpg.create_pool(
                host=db_host,
                port=db_port,
                database=db_name,
                user=db_user,
                password=db_password,
                min_size=5,
                max_size=10,
            )
            self._group_mapping_repository = PostgresGroupMappingRepository(pool)

        return self._group_mapping_repository

    def get_tool_registry(self) -> ToolRegistry:
        """
        Get the tool registry.

        Returns:
            ToolRegistry instance
        """
        if self._tool_registry is None:
            self._tool_registry = ToolRegistry()

        return self._tool_registry

    def get_session_service(self):
        """
        Get the session service based on PERSIST_SESSIONS environment variable.

        Returns:
            DatabaseSessionService for persistent sessions, or None for ephemeral
        """
        if self._session_service is None:
            persist_sessions = os.getenv("PERSIST_SESSIONS", "false").lower() == "true"

            if persist_sessions:
                # Build PostgreSQL connection URL for ADK's DatabaseSessionService
                db_user = os.getenv("DB_USER", "postgres")
                db_password = os.getenv("DB_PASSWORD", "postgres")
                db_host = os.getenv("DB_HOST", "localhost")
                db_port = os.getenv("DB_PORT", "5432")
                db_name = os.getenv("DB_NAME", "agents_db")

                # PostgreSQL connection URL
                db_url = f"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}"

                # Use ADK's built-in DatabaseSessionService
                self._session_service = DatabaseSessionService(db_url=db_url)
            else:
                # Return None to use ephemeral in-memory sessions per request
                self._session_service = None

        return self._session_service

    async def get_agent_service(self) -> AgentService:
        """
        Get the agent service.

        Returns:
            AgentService instance
        """
        if self._agent_service is None:
            repository = await self.init_repository()
            tool_registry = self.get_tool_registry()
            session_service = self.get_session_service()
            self._agent_service = AgentService(repository, tool_registry, session_service)

        return self._agent_service

    async def close(self):
        """Close all resources."""
        if self._repository and isinstance(self._repository, PostgresAgentRepository):
            await self._repository.close()
        if self._corpus_repository and isinstance(self._corpus_repository, PostgresCorpusRepository):
            await self._corpus_repository.pool.close()
        if self._group_mapping_repository and isinstance(self._group_mapping_repository, PostgresGroupMappingRepository):
            await self._group_mapping_repository.pool.close()


# Global container instance
_container: Optional[Container] = None


def get_container() -> Container:
    """
    Get the global container instance.

    Returns:
        Container instance
    """
    global _container
    if _container is None:
        _container = Container()
    return _container


async def close_container():
    """Close the global container."""
    global _container
    if _container is not None:
        await _container.close()
        _container = None
=== ./src/application/di/__init__.py ===
from .container import Container, get_container, close_container

__all__ = ["Container", "get_container", "close_container"]
=== ./src/application/__init__.py ===
=== ./src/application/api/session_routes.py ===
"""API routes for session management."""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Optional

from src.application.di import get_container


router = APIRouter()


class SessionInfo(BaseModel):
    """Session information."""
    session_id: str
    app_name: str
    user_id: str
    agent_id: Optional[str] = None
    status: str
    created_at: Optional[str] = None
    last_message_at: Optional[str] = None


class MessageInfo(BaseModel):
    """Message information."""
    message_id: str
    session_id: str
    role: str
    content: str
    created_at: Optional[str] = None


@router.get("/sessions", response_model=list[dict])
async def list_user_sessions(user_id: str = "default_user"):
    """
    List all sessions for a user.

    Args:
        user_id: The user identifier
    """
    container = get_container()
    agent_service = await container.get_agent_service()

    if not agent_service.persistent_session_service:
        raise HTTPException(
            status_code=501,
            detail="Persistent sessions not enabled. Set PERSIST_SESSIONS=true"
        )

    try:
        import asyncpg

        if not isinstance(agent_service.persistent_session_service, object):
            raise HTTPException(status_code=500, detail="Session service not available")

        pool = agent_service.persistent_session_service.pool

        async with pool.acquire() as conn:
            rows = await conn.fetch(
                """
                SELECT session_id, app_name, user_id, agent_id, status,
                       created_at, last_message_at
                FROM sessions
                WHERE user_id = $1 AND status IN ('active', 'closed')
                ORDER BY created_at DESC
                LIMIT 50
                """,
                user_id
            )

            return [
                {
                    "session_id": row['session_id'],
                    "app_name": row['app_name'],
                    "user_id": row['user_id'],
                    "agent_id": row['agent_id'],
                    "status": row['status'],
                    "created_at": row['created_at'].isoformat() if row['created_at'] else None,
                    "last_message_at": row['last_message_at'].isoformat() if row['last_message_at'] else None
                }
                for row in rows
            ]

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error listing sessions: {str(e)}")


@router.get("/sessions/{session_id}", response_model=dict)
async def get_session(session_id: str, user_id: str = "default_user"):
    """
    Get session details with conversation history.

    Args:
        session_id: The session identifier
        user_id: The user identifier
    """
    container = get_container()
    agent_service = await container.get_agent_service()

    if not agent_service.persistent_session_service:
        raise HTTPException(
            status_code=501,
            detail="Persistent sessions not enabled"
        )

    try:
        pool = agent_service.persistent_session_service.pool

        async with pool.acquire() as conn:
            # Get session
            session_row = await conn.fetchrow(
                """
                SELECT session_id, app_name, user_id, agent_id, status,
                       title, created_at, last_message_at
                FROM sessions
                WHERE session_id = $1 AND user_id = $2
                """,
                session_id, user_id
            )

            if not session_row:
                raise HTTPException(status_code=404, detail="Session not found")

            # Get messages
            message_rows = await conn.fetch(
                """
                SELECT message_id, role, content, created_at,
                       tool_name, model_used
                FROM messages
                WHERE session_id = $1
                ORDER BY created_at ASC
                """,
                session_id
            )

            return {
                "session": {
                    "session_id": session_row['session_id'],
                    "app_name": session_row['app_name'],
                    "user_id": session_row['user_id'],
                    "agent_id": session_row['agent_id'],
                    "status": session_row['status'],
                    "title": session_row['title'],
                    "created_at": session_row['created_at'].isoformat() if session_row['created_at'] else None,
                    "last_message_at": session_row['last_message_at'].isoformat() if session_row['last_message_at'] else None
                },
                "messages": [
                    {
                        "message_id": msg['message_id'],
                        "role": msg['role'],
                        "content": msg['content'],
                        "created_at": msg['created_at'].isoformat() if msg['created_at'] else None,
                        "tool_name": msg['tool_name'],
                        "model_used": msg['model_used']
                    }
                    for msg in message_rows
                ]
            }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error getting session: {str(e)}")


@router.delete("/sessions/{session_id}")
async def delete_session(session_id: str, user_id: str = "default_user"):
    """
    Delete (close) a session.

    Args:
        session_id: The session identifier
        user_id: The user identifier
    """
    container = get_container()
    agent_service = await container.get_agent_service()

    if not agent_service.persistent_session_service:
        raise HTTPException(
            status_code=501,
            detail="Persistent sessions not enabled"
        )

    try:
        pool = agent_service.persistent_session_service.pool

        async with pool.acquire() as conn:
            result = await conn.execute(
                """
                UPDATE sessions
                SET status = 'closed', closed_at = NOW()
                WHERE session_id = $1 AND user_id = $2
                """,
                session_id, user_id
            )

            if result == "UPDATE 0":
                raise HTTPException(status_code=404, detail="Session not found")

            return {"status": "success", "message": f"Session {session_id} closed"}

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error deleting session: {str(e)}")
=== ./src/application/api/teams_routes.py ===
"""
API routes for Microsoft Teams integration.

These routes handle Teams bot webhook callbacks and route messages to GCP agents.
"""
from fastapi import APIRouter, Request, HTTPException
from pydantic import BaseModel
from typing import Optional
import logging

from src.application.di import get_container
from src.services.teams_integration import TeamsAgentIntegration

logger = logging.getLogger(__name__)

router = APIRouter()


class TeamsMessageRequest(BaseModel):
    """Teams message request model."""
    user_message: str
    aad_user_id: str
    user_name: str
    session_id: Optional[str] = None
    persist_session: bool = True  # Enable session persistence by default


class TeamsMessageResponse(BaseModel):
    """Teams message response model."""
    success: bool
    response: str
    agent_name: Optional[str] = None
    agent_area: Optional[str] = None
    user_groups: Optional[list] = None
    session_id: Optional[str] = None
    error: Optional[str] = None


@router.post("/teams/message", response_model=TeamsMessageResponse)
async def process_teams_message(request: TeamsMessageRequest):
    """
    Process a message from Microsoft Teams bot.

    This endpoint:
    1. Receives message from Teams bot
    2. Gets user's Azure AD groups
    3. Routes to appropriate agent based on groups
    4. Returns agent response

    Example Request:
    ```json
    {
        "user_message": "I need help with a contract review",
        "aad_user_id": "12345-67890-abcdef",
        "user_name": "John Doe",
        "session_id": "teams-session-123",
        "persist_session": true
    }
    ```
    """
    try:
        # Get container and services
        container = get_container()
        agent_service = await container.get_agent_service()
        group_mapping_repo = await container.init_group_mapping_repository()

        # Initialize Teams integration
        teams_integration = TeamsAgentIntegration(agent_service, group_mapping_repo)

        # Process the message
        result = await teams_integration.process_message(
            user_message=request.user_message,
            aad_user_id=request.aad_user_id,
            user_name=request.user_name,
            session_id=request.session_id,
            persist_session=request.persist_session
        )

        return TeamsMessageResponse(**result)

    except Exception as e:
        logger.error(f"Error in teams/message endpoint: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/teams/user/{aad_user_id}/agents")
async def get_user_agents(aad_user_id: str):
    """
    Get agent information for a specific user.

    Shows which agent(s) the user can access based on their Azure AD groups.

    Args:
        aad_user_id: Azure AD user object ID

    Returns:
        User's accessible agents and primary agent
    """
    try:
        container = get_container()
        agent_service = await container.get_agent_service()
        group_mapping_repo = await container.init_group_mapping_repository()

        teams_integration = TeamsAgentIntegration(agent_service, group_mapping_repo)

        result = await teams_integration.get_user_agent_info(aad_user_id)

        return result

    except Exception as e:
        logger.error(f"Error in get_user_agents endpoint: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/teams/health")
async def teams_health():
    """Health check for Teams integration."""
    return {
        "status": "healthy",
        "service": "Teams Integration",
        "features": [
            "Azure AD group-based routing",
            "Session persistence",
            "Multi-agent support"
        ]
    }
=== ./src/application/api/group_mapping_routes.py ===
"""API routes for Azure AD group mappings management."""

from typing import List, Optional
from fastapi import APIRouter, HTTPException, status
from pydantic import BaseModel, Field

from src.application.di import get_container


router = APIRouter()


# Request/Response Models
class GroupMappingCreate(BaseModel):
    """Request model for creating a group mapping."""
    group_name: str = Field(..., description="Azure AD group display name")
    area_type: str = Field(..., description="Agent area_type to route to")
    weight: int = Field(default=500, description="Priority weight (higher = higher priority)")
    description: Optional[str] = Field(None, description="Optional description")
    enabled: bool = Field(default=True, description="Whether mapping is active")


class GroupMappingUpdate(BaseModel):
    """Request model for updating a group mapping."""
    area_type: Optional[str] = Field(None, description="New area_type")
    weight: Optional[int] = Field(None, description="New priority weight")
    description: Optional[str] = Field(None, description="New description")
    enabled: Optional[bool] = Field(None, description="New enabled status")


class GroupMappingResponse(BaseModel):
    """Response model for group mapping."""
    mapping_id: int
    group_name: str
    area_type: str
    weight: int
    description: Optional[str]
    enabled: bool
    created_at: Optional[str]
    updated_at: Optional[str]


@router.get("/groups/mappings", response_model=List[GroupMappingResponse])
async def list_group_mappings(enabled_only: bool = True):
    """
    List all Azure AD group to area_type mappings.

    Args:
        enabled_only: Only return enabled mappings

    Returns:
        List of group mappings sorted by weight (descending)
    """
    try:
        container = get_container()
        group_repo = await container.init_group_mapping_repository()

        mappings = await group_repo.get_all_mappings(enabled_only=enabled_only)

        return [
            GroupMappingResponse(
                mapping_id=m.mapping_id,
                group_name=m.group_name,
                area_type=m.area_type,
                weight=m.weight,
                description=m.description,
                enabled=m.enabled,
                created_at=m.created_at.isoformat() if m.created_at else None,
                updated_at=m.updated_at.isoformat() if m.updated_at else None
            )
            for m in mappings
        ]
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error listing group mappings: {str(e)}"
        )


@router.get("/groups/mappings/{mapping_id}", response_model=GroupMappingResponse)
async def get_group_mapping(mapping_id: int):
    """
    Get a specific group mapping by ID.

    Args:
        mapping_id: Mapping ID to retrieve

    Returns:
        Group mapping details
    """
    try:
        container = get_container()
        group_repo = await container.init_group_mapping_repository()

        mapping = await group_repo.get_mapping_by_id(mapping_id)

        if not mapping:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Group mapping with ID {mapping_id} not found"
            )

        return GroupMappingResponse(
            mapping_id=mapping.mapping_id,
            group_name=mapping.group_name,
            area_type=mapping.area_type,
            weight=mapping.weight,
            description=mapping.description,
            enabled=mapping.enabled,
            created_at=mapping.created_at.isoformat() if mapping.created_at else None,
            updated_at=mapping.updated_at.isoformat() if mapping.updated_at else None
        )
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error retrieving group mapping: {str(e)}"
        )


@router.post("/groups/mappings", response_model=GroupMappingResponse, status_code=status.HTTP_201_CREATED)
async def create_group_mapping(mapping: GroupMappingCreate):
    """
    Create a new Azure AD group to area_type mapping.

    Args:
        mapping: Group mapping details

    Returns:
        Created group mapping
    """
    try:
        container = get_container()
        group_repo = await container.init_group_mapping_repository()

        # Check if group name already exists
        existing = await group_repo.get_mapping_by_group_name(mapping.group_name)
        if existing:
            raise HTTPException(
                status_code=status.HTTP_409_CONFLICT,
                detail=f"Group mapping for '{mapping.group_name}' already exists"
            )

        created = await group_repo.create_mapping(
            group_name=mapping.group_name,
            area_type=mapping.area_type,
            weight=mapping.weight,
            description=mapping.description,
            enabled=mapping.enabled
        )

        return GroupMappingResponse(
            mapping_id=created.mapping_id,
            group_name=created.group_name,
            area_type=created.area_type,
            weight=created.weight,
            description=created.description,
            enabled=created.enabled,
            created_at=created.created_at.isoformat() if created.created_at else None,
            updated_at=created.updated_at.isoformat() if created.updated_at else None
        )
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error creating group mapping: {str(e)}"
        )


@router.put("/groups/mappings/{mapping_id}", response_model=GroupMappingResponse)
async def update_group_mapping(mapping_id: int, mapping: GroupMappingUpdate):
    """
    Update an existing group mapping.

    Args:
        mapping_id: Mapping ID to update
        mapping: Updated mapping details

    Returns:
        Updated group mapping
    """
    try:
        container = get_container()
        group_repo = await container.init_group_mapping_repository()

        updated = await group_repo.update_mapping(
            mapping_id=mapping_id,
            area_type=mapping.area_type,
            weight=mapping.weight,
            description=mapping.description,
            enabled=mapping.enabled
        )

        if not updated:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Group mapping with ID {mapping_id} not found"
            )

        return GroupMappingResponse(
            mapping_id=updated.mapping_id,
            group_name=updated.group_name,
            area_type=updated.area_type,
            weight=updated.weight,
            description=updated.description,
            enabled=updated.enabled,
            created_at=updated.created_at.isoformat() if updated.created_at else None,
            updated_at=updated.updated_at.isoformat() if updated.updated_at else None
        )
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error updating group mapping: {str(e)}"
        )


@router.delete("/groups/mappings/{mapping_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_group_mapping(mapping_id: int):
    """
    Delete a group mapping.

    Args:
        mapping_id: Mapping ID to delete

    Returns:
        No content on success
    """
    try:
        container = get_container()
        group_repo = await container.init_group_mapping_repository()

        deleted = await group_repo.delete_mapping(mapping_id)

        if not deleted:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Group mapping with ID {mapping_id} not found"
            )

        return None
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error deleting group mapping: {str(e)}"
        )


@router.get("/groups/mappings/by-group/{group_name}", response_model=GroupMappingResponse)
async def get_group_mapping_by_name(group_name: str):
    """
    Get a group mapping by Azure AD group name.

    Args:
        group_name: Azure AD group display name

    Returns:
        Group mapping details
    """
    try:
        container = get_container()
        group_repo = await container.init_group_mapping_repository()

        mapping = await group_repo.get_mapping_by_group_name(group_name)

        if not mapping:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Group mapping for '{group_name}' not found"
            )

        return GroupMappingResponse(
            mapping_id=mapping.mapping_id,
            group_name=mapping.group_name,
            area_type=mapping.area_type,
            weight=mapping.weight,
            description=mapping.description,
            enabled=mapping.enabled,
            created_at=mapping.created_at.isoformat() if mapping.created_at else None,
            updated_at=mapping.updated_at.isoformat() if mapping.updated_at else None
        )
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error retrieving group mapping: {str(e)}"
        )
=== ./src/application/api/routes.py ===
"""API routes for the agent service."""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Optional

from src.application.di import get_container


router = APIRouter()


class InvokeRequest(BaseModel):
    """Request model for invoking an agent."""
    agent_id: str = None
    agent_name: str = None
    prompt: str
    user_id: str = "default_user"
    session_id: Optional[str] = None
    persist_session: bool = False  # Enable to save conversation history


class InvokeResponse(BaseModel):
    """Response model for agent invocation."""
    response: str
    agent_id: Optional[str] = None
    agent_name: Optional[str] = None
    session_id: Optional[str] = None


class AgentInfo(BaseModel):
    """Information about an agent."""
    agent_id: str
    name: str
    description: str
    model: str
    tools_count: int


@router.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy"}


@router.post("/invoke", response_model=InvokeResponse)
async def invoke_agent(request: InvokeRequest):
    """
    Invoke an agent with a prompt.

    Either agent_id or agent_name must be provided.
    Set persist_session=true to save conversation history.
    """
    if not request.agent_id and not request.agent_name:
        raise HTTPException(
            status_code=400,
            detail="Either agent_id or agent_name must be provided"
        )

    container = get_container()
    agent_service = await container.get_agent_service()

    try:
        if request.agent_id:
            response = await agent_service.invoke_agent(
                request.agent_id,
                request.prompt,
                user_id=request.user_id,
                session_id=request.session_id,
                persist_session=request.persist_session
            )
            return InvokeResponse(
                response=response,
                agent_id=request.agent_id,
                session_id=request.session_id
            )
        else:
            response = await agent_service.invoke_agent_by_name(
                request.agent_name,
                request.prompt,
                user_id=request.user_id,
                session_id=request.session_id,
                persist_session=request.persist_session
            )
            return InvokeResponse(
                response=response,
                agent_name=request.agent_name,
                session_id=request.session_id
            )

    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error invoking agent: {str(e)}")


@router.get("/agents", response_model=list[AgentInfo])
async def list_agents(enabled_only: bool = True):
    """
    List all available agents.

    Args:
        enabled_only: If True, return only enabled agents
    """
    container = get_container()
    agent_service = await container.get_agent_service()

    try:
        configs = await agent_service.repository.list_agents(enabled_only)

        return [
            AgentInfo(
                agent_id=config.agent_id,
                name=config.name,
                description=config.description,
                model=config.model.model_name,
                tools_count=len(config.tools)
            )
            for config in configs
        ]

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error listing agents: {str(e)}")


@router.get("/agents/{agent_id}")
async def get_agent(agent_id: str):
    """Get detailed information about an agent."""
    container = get_container()
    agent_service = await container.get_agent_service()

    try:
        config = await agent_service.repository.get_agent_by_id(agent_id)

        if not config:
            raise HTTPException(status_code=404, detail="Agent not found")

        return {
            "agent_id": config.agent_id,
            "name": config.name,
            "description": config.description,
            "instruction": config.instruction,
            "model": {
                "model_name": config.model.model_name,
                "temperature": config.model.temperature,
                "max_tokens": config.model.max_tokens,
            },
            "tools": [
                {
                    "tool_id": tool.tool_id,
                    "tool_name": tool.tool_name,
                    "tool_type": tool.tool_type,
                    "description": tool.description,
                }
                for tool in config.tools
            ],
            "sub_agent_ids": config.sub_agent_ids,
            "enabled": config.enabled,
            "metadata": config.metadata,
        }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error getting agent: {str(e)}")


@router.post("/agents/{agent_id}/reload")
async def reload_agent(agent_id: str):
    """Reload an agent configuration from the database."""
    container = get_container()
    agent_service = await container.get_agent_service()

    try:
        agent = await agent_service.reload_agent(agent_id)

        if not agent:
            raise HTTPException(status_code=404, detail="Agent not found")

        return {"status": "success", "message": f"Agent {agent_id} reloaded"}

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error reloading agent: {str(e)}")
=== ./src/application/api/__init__.py ===
from .routes import router

__all__ = ["router"]
=== ./src/infrastructure/adapters/postgres/postgres_agent_repository.py ===
"""PostgreSQL adapter implementation of AgentRepository port."""

import json
from typing import Optional
import asyncpg
from asyncpg import Pool

from src.domain.models import AgentConfig, ToolConfig, ModelConfig, CorpusConfig
from src.domain.ports import AgentRepository


class PostgresAgentRepository(AgentRepository):
    """
    PostgreSQL implementation of the AgentRepository port.

    This adapter connects to a PostgreSQL database and implements
    all methods defined in the AgentRepository interface.
    """

    def __init__(self, pool: Pool):
        """
        Initialize the PostgreSQL repository.

        Args:
            pool: AsyncPG connection pool
        """
        self.pool = pool

    @classmethod
    async def create(
        cls,
        host: str,
        port: int,
        database: str,
        user: str,
        password: str,
        min_size: int = 10,
        max_size: int = 20,
    ) -> "PostgresAgentRepository":
        """
        Create a new PostgreSQL repository with a connection pool.

        Args:
            host: Database host
            port: Database port
            database: Database name
            user: Database user
            password: Database password
            min_size: Minimum pool size
            max_size: Maximum pool size

        Returns:
            PostgresAgentRepository instance
        """
        pool = await asyncpg.create_pool(
            host=host,
            port=port,
            database=database,
            user=user,
            password=password,
            min_size=min_size,
            max_size=max_size,
        )
        return cls(pool)

    async def close(self):
        """Close the connection pool."""
        await self.pool.close()

    async def get_agent_by_id(self, agent_id: str) -> Optional[AgentConfig]:
        """Get agent configuration by ID."""
        query = """
            SELECT
                a.agent_id,
                a.name,
                a.instruction,
                a.description,
                a.enabled,
                a.metadata,
                a.agent_type,
                a.area_type,
                a.model_name,
                a.temperature,
                a.max_tokens,
                a.top_p,
                a.top_k,
                COALESCE(
                    json_agg(
                        json_build_object(
                            'tool_id', t.tool_id,
                            'tool_name', t.tool_name,
                            'tool_type', t.tool_type,
                            'function_name', t.function_name,
                            'parameters', t.parameters,
                            'description', t.description,
                            'enabled', t.enabled
                        )
                    ) FILTER (WHERE t.tool_id IS NOT NULL),
                    '[]'
                ) as tools,
                COALESCE(
                    json_agg(
                        json_build_object(
                            'corpus_id', c.corpus_id,
                            'corpus_name', c.corpus_name,
                            'display_name', c.display_name,
                            'description', c.description,
                            'vertex_corpus_name', c.vertex_corpus_name,
                            'embedding_model', c.embedding_model,
                            'vector_db_type', c.vector_db_type,
                            'vector_db_config', c.vector_db_config,
                            'document_count', c.document_count,
                            'chunk_size', c.chunk_size,
                            'chunk_overlap', c.chunk_overlap,
                            'priority', ac.priority,
                            'metadata', c.metadata,
                            'enabled', c.enabled
                        )
                    ) FILTER (WHERE c.corpus_id IS NOT NULL),
                    '[]'
                ) as corpuses,
                COALESCE(
                    array_agg(DISTINCT sa.sub_agent_id) FILTER (WHERE sa.sub_agent_id IS NOT NULL),
                    ARRAY[]::text[]
                ) as sub_agent_ids
            FROM agents a
            LEFT JOIN agent_tools at ON a.agent_id = at.agent_id
            LEFT JOIN tools t ON at.tool_id = t.tool_id
            LEFT JOIN agent_corpuses ac ON a.agent_id = ac.agent_id
            LEFT JOIN corpuses c ON ac.corpus_id = c.corpus_id
            LEFT JOIN agent_sub_agents sa ON a.agent_id = sa.parent_agent_id
            WHERE a.agent_id = $1
            GROUP BY a.agent_id
        """

        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(query, agent_id)
            if not row:
                return None
            return self._row_to_agent_config(row)

    async def get_agent_by_name(self, name: str) -> Optional[AgentConfig]:
        """Get agent configuration by name."""
        query = """
            SELECT
                a.agent_id,
                a.name,
                a.instruction,
                a.description,
                a.enabled,
                a.metadata,
                a.agent_type,
                a.area_type,
                a.model_name,
                a.temperature,
                a.max_tokens,
                a.top_p,
                a.top_k,
                COALESCE(
                    json_agg(
                        json_build_object(
                            'tool_id', t.tool_id,
                            'tool_name', t.tool_name,
                            'tool_type', t.tool_type,
                            'function_name', t.function_name,
                            'parameters', t.parameters,
                            'description', t.description,
                            'enabled', t.enabled
                        )
                    ) FILTER (WHERE t.tool_id IS NOT NULL),
                    '[]'
                ) as tools,
                COALESCE(
                    json_agg(
                        json_build_object(
                            'corpus_id', c.corpus_id,
                            'corpus_name', c.corpus_name,
                            'display_name', c.display_name,
                            'description', c.description,
                            'vertex_corpus_name', c.vertex_corpus_name,
                            'embedding_model', c.embedding_model,
                            'vector_db_type', c.vector_db_type,
                            'vector_db_config', c.vector_db_config,
                            'document_count', c.document_count,
                            'chunk_size', c.chunk_size,
                            'chunk_overlap', c.chunk_overlap,
                            'priority', ac.priority,
                            'metadata', c.metadata,
                            'enabled', c.enabled
                        )
                    ) FILTER (WHERE c.corpus_id IS NOT NULL),
                    '[]'
                ) as corpuses,
                COALESCE(
                    array_agg(DISTINCT sa.sub_agent_id) FILTER (WHERE sa.sub_agent_id IS NOT NULL),
                    ARRAY[]::text[]
                ) as sub_agent_ids
            FROM agents a
            LEFT JOIN agent_tools at ON a.agent_id = at.agent_id
            LEFT JOIN tools t ON at.tool_id = t.tool_id
            LEFT JOIN agent_corpuses ac ON a.agent_id = ac.agent_id
            LEFT JOIN corpuses c ON ac.corpus_id = c.corpus_id
            LEFT JOIN agent_sub_agents sa ON a.agent_id = sa.parent_agent_id
            WHERE a.name = $1
            GROUP BY a.agent_id
        """

        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(query, name)
            if not row:
                return None
            return self._row_to_agent_config(row)

    async def list_agents(self, enabled_only: bool = True) -> list[AgentConfig]:
        """List all agent configurations."""
        query = """
            SELECT
                a.agent_id,
                a.name,
                a.instruction,
                a.description,
                a.enabled,
                a.metadata,
                a.agent_type,
                a.area_type,
                a.model_name,
                a.temperature,
                a.max_tokens,
                a.top_p,
                a.top_k,
                COALESCE(
                    json_agg(
                        json_build_object(
                            'tool_id', t.tool_id,
                            'tool_name', t.tool_name,
                            'tool_type', t.tool_type,
                            'function_name', t.function_name,
                            'parameters', t.parameters,
                            'description', t.description,
                            'enabled', t.enabled
                        )
                    ) FILTER (WHERE t.tool_id IS NOT NULL),
                    '[]'
                ) as tools,
                COALESCE(
                    json_agg(
                        json_build_object(
                            'corpus_id', c.corpus_id,
                            'corpus_name', c.corpus_name,
                            'display_name', c.display_name,
                            'description', c.description,
                            'vertex_corpus_name', c.vertex_corpus_name,
                            'embedding_model', c.embedding_model,
                            'vector_db_type', c.vector_db_type,
                            'vector_db_config', c.vector_db_config,
                            'document_count', c.document_count,
                            'chunk_size', c.chunk_size,
                            'chunk_overlap', c.chunk_overlap,
                            'priority', ac.priority,
                            'metadata', c.metadata,
                            'enabled', c.enabled
                        )
                    ) FILTER (WHERE c.corpus_id IS NOT NULL),
                    '[]'
                ) as corpuses,
                COALESCE(
                    array_agg(DISTINCT sa.sub_agent_id) FILTER (WHERE sa.sub_agent_id IS NOT NULL),
                    ARRAY[]::text[]
                ) as sub_agent_ids
            FROM agents a
            LEFT JOIN agent_tools at ON a.agent_id = at.agent_id
            LEFT JOIN tools t ON at.tool_id = t.tool_id
            LEFT JOIN agent_corpuses ac ON a.agent_id = ac.agent_id
            LEFT JOIN corpuses c ON ac.corpus_id = c.corpus_id
            LEFT JOIN agent_sub_agents sa ON a.agent_id = sa.parent_agent_id
        """

        if enabled_only:
            query += " WHERE a.enabled = true"

        query += " GROUP BY a.agent_id ORDER BY a.name"

        async with self.pool.acquire() as conn:
            rows = await conn.fetch(query)
            return [self._row_to_agent_config(row) for row in rows]

    async def get_tools_for_agent(self, agent_id: str) -> list[ToolConfig]:
        """Get all tools for a specific agent."""
        query = """
            SELECT
                t.tool_id,
                t.tool_name,
                t.tool_type,
                t.function_name,
                t.parameters,
                t.description,
                t.enabled
            FROM tools t
            INNER JOIN agent_tools at ON t.tool_id = at.tool_id
            WHERE at.agent_id = $1 AND t.enabled = true
            ORDER BY t.tool_name
        """

        async with self.pool.acquire() as conn:
            rows = await conn.fetch(query, agent_id)
            return [self._row_to_tool_config(row) for row in rows]

    async def get_tool_by_id(self, tool_id: str) -> Optional[ToolConfig]:
        """Get tool configuration by ID."""
        query = """
            SELECT
                tool_id,
                tool_name,
                tool_type,
                function_name,
                parameters,
                description,
                enabled
            FROM tools
            WHERE tool_id = $1
        """

        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(query, tool_id)
            if not row:
                return None
            return self._row_to_tool_config(row)

    async def save_agent(self, agent: AgentConfig) -> AgentConfig:
        """Save or update an agent configuration."""
        query = """
            INSERT INTO agents (
                agent_id, name, instruction, description, enabled, metadata,
                agent_type, area_type,
                model_name, temperature, max_tokens, top_p, top_k
            )
            VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
            ON CONFLICT (agent_id) DO UPDATE SET
                name = EXCLUDED.name,
                instruction = EXCLUDED.instruction,
                description = EXCLUDED.description,
                enabled = EXCLUDED.enabled,
                metadata = EXCLUDED.metadata,
                agent_type = EXCLUDED.agent_type,
                area_type = EXCLUDED.area_type,
                model_name = EXCLUDED.model_name,
                temperature = EXCLUDED.temperature,
                max_tokens = EXCLUDED.max_tokens,
                top_p = EXCLUDED.top_p,
                top_k = EXCLUDED.top_k,
                updated_at = NOW()
            RETURNING *
        """

        async with self.pool.acquire() as conn:
            async with conn.transaction():
                await conn.execute(
                    query,
                    agent.agent_id,
                    agent.name,
                    agent.instruction,
                    agent.description,
                    agent.enabled,
                    json.dumps(agent.metadata),
                    agent.agent_type,
                    agent.area_type,
                    agent.model.model_name,
                    agent.model.temperature,
                    agent.model.max_tokens,
                    agent.model.top_p,
                    agent.model.top_k,
                )

                # Delete existing tool associations
                await conn.execute(
                    "DELETE FROM agent_tools WHERE agent_id = $1", agent.agent_id
                )

                # Insert new tool associations
                if agent.tools:
                    await conn.executemany(
                        "INSERT INTO agent_tools (agent_id, tool_id) VALUES ($1, $2)",
                        [(agent.agent_id, tool.tool_id) for tool in agent.tools],
                    )

                # Delete existing corpus associations
                await conn.execute(
                    "DELETE FROM agent_corpuses WHERE agent_id = $1",
                    agent.agent_id,
                )

                # Insert new corpus associations
                if agent.corpuses:
                    await conn.executemany(
                        "INSERT INTO agent_corpuses (agent_id, corpus_id, priority) VALUES ($1, $2, $3)",
                        [(agent.agent_id, corpus.corpus_id, corpus.priority) for corpus in agent.corpuses],
                    )

                # Delete existing sub-agent associations
                await conn.execute(
                    "DELETE FROM agent_sub_agents WHERE parent_agent_id = $1",
                    agent.agent_id,
                )

                # Insert new sub-agent associations
                if agent.sub_agent_ids:
                    await conn.executemany(
                        "INSERT INTO agent_sub_agents (parent_agent_id, sub_agent_id) VALUES ($1, $2)",
                        [(agent.agent_id, sub_id) for sub_id in agent.sub_agent_ids],
                    )

        return agent

    async def delete_agent(self, agent_id: str) -> bool:
        """Delete an agent configuration."""
        query = "DELETE FROM agents WHERE agent_id = $1"

        async with self.pool.acquire() as conn:
            result = await conn.execute(query, agent_id)
            return result == "DELETE 1"

    def _row_to_agent_config(self, row) -> AgentConfig:
        """Convert a database row to AgentConfig."""
        model_config = ModelConfig(
            model_name=row["model_name"],
            temperature=row["temperature"],
            max_tokens=row["max_tokens"],
            top_p=row["top_p"],
            top_k=row["top_k"],
        )

        tools = []
        if row["tools"]:
            tools_data = row["tools"] if isinstance(row["tools"], list) else json.loads(row["tools"])
            tools = [
                ToolConfig(
                    tool_id=t["tool_id"],
                    tool_name=t["tool_name"],
                    tool_type=t["tool_type"],
                    function_name=t.get("function_name"),
                    parameters=t.get("parameters", {}),
                    description=t.get("description"),
                    enabled=t.get("enabled", True),
                )
                for t in tools_data
            ]

        corpuses = []
        if row.get("corpuses"):
            corpuses_data = row["corpuses"] if isinstance(row["corpuses"], list) else json.loads(row["corpuses"])
            corpuses = [
                CorpusConfig(
                    corpus_id=c["corpus_id"],
                    corpus_name=c["corpus_name"],
                    display_name=c["display_name"],
                    description=c.get("description"),
                    vertex_corpus_name=c.get("vertex_corpus_name"),
                    embedding_model=c.get("embedding_model", "text-embedding-005"),
                    vector_db_type=c.get("vector_db_type", "vertex_rag"),
                    vector_db_config=c.get("vector_db_config", {}),
                    document_count=c.get("document_count", 0),
                    chunk_size=c.get("chunk_size", 1000),
                    chunk_overlap=c.get("chunk_overlap", 200),
                    priority=c.get("priority", 1),
                    metadata=c.get("metadata", {}),
                    enabled=c.get("enabled", True),
                )
                for c in corpuses_data
            ]

        metadata = row["metadata"]
        if isinstance(metadata, str):
            metadata = json.loads(metadata)

        return AgentConfig(
            agent_id=row["agent_id"],
            name=row["name"],
            model=model_config,
            instruction=row["instruction"],
            description=row["description"],
            agent_type=row.get("agent_type", "assistant"),
            area_type=row.get("area_type", "general"),
            tools=tools,
            corpuses=corpuses,
            sub_agent_ids=row["sub_agent_ids"] or [],
            enabled=row["enabled"],
            metadata=metadata or {},
        )

    def _row_to_tool_config(self, row) -> ToolConfig:
        """Convert a database row to ToolConfig."""
        parameters = row["parameters"]
        if isinstance(parameters, str):
            parameters = json.loads(parameters)

        return ToolConfig(
            tool_id=row["tool_id"],
            tool_name=row["tool_name"],
            tool_type=row["tool_type"],
            function_name=row.get("function_name"),
            parameters=parameters or {},
            description=row.get("description"),
            enabled=row.get("enabled", True),
        )
=== ./src/infrastructure/adapters/postgres/schema.sql ===
-- Database schema for agent configuration

-- Agents table
CREATE TABLE IF NOT EXISTS agents (
    agent_id VARCHAR(255) PRIMARY KEY,
    name VARCHAR(255) NOT NULL UNIQUE,
    instruction TEXT NOT NULL,
    description TEXT NOT NULL,
    enabled BOOLEAN DEFAULT TRUE,
    metadata JSONB DEFAULT '{}'::jsonb,
    -- Agent classification
    agent_type VARCHAR(50) DEFAULT 'assistant' CHECK (agent_type IN ('assistant', 'coordinator', 'specialist', 'rag', 'tool')),
    area_type VARCHAR(50) DEFAULT 'general',  -- Removed constraint to match Azure AD groups dynamically
    -- Model configuration
    model_name VARCHAR(100) NOT NULL,
    temperature DECIMAL(3, 2) DEFAULT 0.7,
    max_tokens INTEGER,
    top_p DECIMAL(3, 2),
    top_k INTEGER,
    -- Timestamps
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Tools table
CREATE TABLE IF NOT EXISTS tools (
    tool_id VARCHAR(255) PRIMARY KEY,
    tool_name VARCHAR(255) NOT NULL UNIQUE,
    tool_type VARCHAR(50) NOT NULL CHECK (tool_type IN ('function', 'builtin', 'third_party', 'rag', 'agent')),
    function_name VARCHAR(255),
    parameters JSONB DEFAULT '{}'::jsonb,
    description TEXT,
    enabled BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- RAG Corpuses table
CREATE TABLE IF NOT EXISTS corpuses (
    corpus_id VARCHAR(255) PRIMARY KEY,
    corpus_name VARCHAR(255) NOT NULL UNIQUE,
    display_name VARCHAR(255) NOT NULL,
    description TEXT,
    -- Vertex AI RAG corpus resource name
    vertex_corpus_name VARCHAR(500),
    -- Embedding model configuration
    embedding_model VARCHAR(100) DEFAULT 'text-embedding-005',
    -- Vector database settings
    vector_db_type VARCHAR(50) DEFAULT 'vertex_rag' CHECK (vector_db_type IN ('vertex_rag', 'qdrant', 'pinecone', 'weaviate')),
    vector_db_config JSONB DEFAULT '{}'::jsonb,
    -- Corpus metadata
    document_count INTEGER DEFAULT 0,
    chunk_size INTEGER DEFAULT 1000,
    chunk_overlap INTEGER DEFAULT 200,
    metadata JSONB DEFAULT '{}'::jsonb,
    enabled BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Agent-Corpus association table (many-to-many)
CREATE TABLE IF NOT EXISTS agent_corpuses (
    agent_id VARCHAR(255) REFERENCES agents(agent_id) ON DELETE CASCADE,
    corpus_id VARCHAR(255) REFERENCES corpuses(corpus_id) ON DELETE CASCADE,
    priority INTEGER DEFAULT 1,
    metadata JSONB DEFAULT '{}'::jsonb,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    PRIMARY KEY (agent_id, corpus_id)
);

-- Agent-Tool association table (many-to-many)
CREATE TABLE IF NOT EXISTS agent_tools (
    agent_id VARCHAR(255) REFERENCES agents(agent_id) ON DELETE CASCADE,
    tool_id VARCHAR(255) REFERENCES tools(tool_id) ON DELETE CASCADE,
    PRIMARY KEY (agent_id, tool_id)
);

-- Agent hierarchy table (for sub-agents)
CREATE TABLE IF NOT EXISTS agent_sub_agents (
    parent_agent_id VARCHAR(255) REFERENCES agents(agent_id) ON DELETE CASCADE,
    sub_agent_id VARCHAR(255) REFERENCES agents(agent_id) ON DELETE CASCADE,
    PRIMARY KEY (parent_agent_id, sub_agent_id),
    CHECK (parent_agent_id != sub_agent_id)
);

-- Indexes for better query performance
CREATE INDEX IF NOT EXISTS idx_agents_name ON agents(name);
CREATE INDEX IF NOT EXISTS idx_agents_enabled ON agents(enabled);
CREATE INDEX IF NOT EXISTS idx_agents_type ON agents(agent_type);
CREATE INDEX IF NOT EXISTS idx_agents_area ON agents(area_type);
CREATE INDEX IF NOT EXISTS idx_agents_type_area ON agents(agent_type, area_type);
CREATE INDEX IF NOT EXISTS idx_tools_name ON tools(tool_name);
CREATE INDEX IF NOT EXISTS idx_tools_type ON tools(tool_type);
CREATE INDEX IF NOT EXISTS idx_agent_tools_agent_id ON agent_tools(agent_id);
CREATE INDEX IF NOT EXISTS idx_agent_tools_tool_id ON agent_tools(tool_id);
CREATE INDEX IF NOT EXISTS idx_sub_agents_parent ON agent_sub_agents(parent_agent_id);
CREATE INDEX IF NOT EXISTS idx_sub_agents_child ON agent_sub_agents(sub_agent_id);
CREATE INDEX IF NOT EXISTS idx_corpuses_name ON corpuses(corpus_name);
CREATE INDEX IF NOT EXISTS idx_corpuses_enabled ON corpuses(enabled);
CREATE INDEX IF NOT EXISTS idx_agent_corpuses_agent_id ON agent_corpuses(agent_id);
CREATE INDEX IF NOT EXISTS idx_agent_corpuses_corpus_id ON agent_corpuses(corpus_id);

-- Sample data for testing
INSERT INTO agents (agent_id, name, instruction, description, model_name, temperature, agent_type, area_type)
VALUES
    ('agent-001', 'search_assistant', 'You are a helpful assistant that can search the web and answer questions.', 'An assistant that can search the web.', 'gemini-2.5-flash', 0.7, 'assistant', 'general'),
    ('agent-002', 'data_analyst', 'You are a data analyst that can process and analyze data.', 'A data analysis expert.', 'gemini-2.5-pro', 0.5, 'specialist', 'data_analysis'),
    ('agent-003', 'marketing_rag_agent', 'You are a marketing expert with access to company marketing materials, campaigns, and best practices. Use the RAG tool to retrieve relevant information from the marketing corpus.', 'Marketing specialist with RAG capabilities.', 'gemini-2.5-pro', 0.7, 'rag', 'marketing'),
    ('agent-004', 'legal_advisor', 'You are a legal advisor with access to company legal documents, contracts, and compliance information. Use the RAG tool to retrieve relevant legal information.', 'Legal advisor with document access.', 'gemini-2.5-pro', 0.5, 'rag', 'legal'),
    ('agent-005', 'dev_assistant', 'You are a developer assistant with access to code documentation, API references, and technical guides. Help developers with code-related questions.', 'Developer assistant with technical documentation access.', 'gemini-2.5-flash', 0.6, 'rag', 'developer')
ON CONFLICT (agent_id) DO NOTHING;

INSERT INTO tools (tool_id, tool_name, tool_type, function_name, description)
VALUES
    ('tool-001', 'web_search', 'function', 'search_web', 'Search the web for information'),
    ('tool-002', 'calculate', 'function', 'calculate', 'Perform mathematical calculations'),
    ('tool-003', 'get_weather', 'function', 'get_weather', 'Get current weather information'),
    ('tool-004', 'rag_search', 'rag', 'vertex_rag_retrieval', 'Retrieve information from RAG corpus using Vertex AI RAG Engine'),
    ('tool-005', 'data_analyst_tool', 'agent', 'agent-002', 'Delegate data analysis tasks to the data analyst agent')
ON CONFLICT (tool_id) DO NOTHING;

INSERT INTO agent_tools (agent_id, tool_id)
VALUES
    ('agent-001', 'tool-001'),
    ('agent-001', 'tool-003'),
    ('agent-002', 'tool-002'),
    ('agent-003', 'tool-004'),
    ('agent-004', 'tool-004'),
    ('agent-005', 'tool-004')
ON CONFLICT (agent_id, tool_id) DO NOTHING;

-- Sample corpuses
INSERT INTO corpuses (corpus_id, corpus_name, display_name, description, embedding_model, document_count)
VALUES
    ('corpus-001', 'marketing_knowledge', 'Marketing Knowledge Base', 'Marketing campaigns, strategies, and best practices', 'text-embedding-005', 0),
    ('corpus-002', 'legal_documents', 'Legal Documents Repository', 'Contracts, compliance docs, and legal guidelines', 'text-embedding-005', 0),
    ('corpus-003', 'technical_docs', 'Technical Documentation', 'API docs, code samples, and technical guides', 'text-embedding-005', 0),
    ('corpus-004', 'sales_playbook', 'Sales Playbook', 'Sales strategies, scripts, and customer insights', 'text-embedding-005', 0),
    ('corpus-005', 'operations_manual', 'Operations Manual', 'Standard operating procedures and workflows', 'text-embedding-005', 0)
ON CONFLICT (corpus_id) DO NOTHING;

-- Assign corpuses to agents
INSERT INTO agent_corpuses (agent_id, corpus_id, priority)
VALUES
    -- Marketing agent gets marketing, sales, and operations knowledge
    ('agent-003', 'corpus-001', 1),
    ('agent-003', 'corpus-004', 2),
    ('agent-003', 'corpus-005', 3),
    -- Legal advisor gets legal and operations knowledge
    ('agent-004', 'corpus-002', 1),
    ('agent-004', 'corpus-005', 2),
    -- Developer assistant gets technical docs
    ('agent-005', 'corpus-003', 1)
ON CONFLICT (agent_id, corpus_id) DO NOTHING;
=== ./src/infrastructure/adapters/postgres/postgres_corpus_repository.py ===
"""PostgreSQL adapter implementation of CorpusRepository port."""

import json
from typing import Optional
from asyncpg import Pool

from src.domain.models import CorpusConfig
from src.domain.ports import CorpusRepository


class PostgresCorpusRepository(CorpusRepository):
    """
    PostgreSQL implementation of the CorpusRepository port.

    This adapter connects to a PostgreSQL database and implements
    all methods defined in the CorpusRepository interface.
    """

    def __init__(self, pool: Pool):
        """
        Initialize the PostgreSQL corpus repository.

        Args:
            pool: AsyncPG connection pool
        """
        self.pool = pool

    async def get_corpus_by_id(self, corpus_id: str) -> Optional[CorpusConfig]:
        """Get corpus configuration by ID."""
        query = """
            SELECT
                corpus_id,
                corpus_name,
                display_name,
                description,
                vertex_corpus_name,
                embedding_model,
                vector_db_type,
                vector_db_config,
                document_count,
                chunk_size,
                chunk_overlap,
                metadata,
                enabled
            FROM corpuses
            WHERE corpus_id = $1
        """

        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(query, corpus_id)
            if not row:
                return None
            return self._row_to_corpus_config(row)

    async def get_corpus_by_name(self, corpus_name: str) -> Optional[CorpusConfig]:
        """Get corpus configuration by name."""
        query = """
            SELECT
                corpus_id,
                corpus_name,
                display_name,
                description,
                vertex_corpus_name,
                embedding_model,
                vector_db_type,
                vector_db_config,
                document_count,
                chunk_size,
                chunk_overlap,
                metadata,
                enabled
            FROM corpuses
            WHERE corpus_name = $1
        """

        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(query, corpus_name)
            if not row:
                return None
            return self._row_to_corpus_config(row)

    async def list_corpuses(self, enabled_only: bool = True) -> list[CorpusConfig]:
        """List all corpus configurations."""
        query = """
            SELECT
                corpus_id,
                corpus_name,
                display_name,
                description,
                vertex_corpus_name,
                embedding_model,
                vector_db_type,
                vector_db_config,
                document_count,
                chunk_size,
                chunk_overlap,
                metadata,
                enabled
            FROM corpuses
        """

        if enabled_only:
            query += " WHERE enabled = true"

        query += " ORDER BY corpus_name"

        async with self.pool.acquire() as conn:
            rows = await conn.fetch(query)
            return [self._row_to_corpus_config(row) for row in rows]

    async def get_corpuses_for_agent(self, agent_id: str) -> list[CorpusConfig]:
        """Get all corpuses for a specific agent."""
        query = """
            SELECT
                c.corpus_id,
                c.corpus_name,
                c.display_name,
                c.description,
                c.vertex_corpus_name,
                c.embedding_model,
                c.vector_db_type,
                c.vector_db_config,
                c.document_count,
                c.chunk_size,
                c.chunk_overlap,
                c.metadata,
                c.enabled,
                ac.priority
            FROM corpuses c
            INNER JOIN agent_corpuses ac ON c.corpus_id = ac.corpus_id
            WHERE ac.agent_id = $1 AND c.enabled = true
            ORDER BY ac.priority ASC, c.corpus_name
        """

        async with self.pool.acquire() as conn:
            rows = await conn.fetch(query, agent_id)
            return [self._row_to_corpus_config(row) for row in rows]

    async def save_corpus(self, corpus: CorpusConfig) -> CorpusConfig:
        """Save or update a corpus configuration."""
        query = """
            INSERT INTO corpuses (
                corpus_id, corpus_name, display_name, description,
                vertex_corpus_name, embedding_model, vector_db_type,
                vector_db_config, document_count, chunk_size, chunk_overlap,
                metadata, enabled
            )
            VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
            ON CONFLICT (corpus_id) DO UPDATE SET
                corpus_name = EXCLUDED.corpus_name,
                display_name = EXCLUDED.display_name,
                description = EXCLUDED.description,
                vertex_corpus_name = EXCLUDED.vertex_corpus_name,
                embedding_model = EXCLUDED.embedding_model,
                vector_db_type = EXCLUDED.vector_db_type,
                vector_db_config = EXCLUDED.vector_db_config,
                document_count = EXCLUDED.document_count,
                chunk_size = EXCLUDED.chunk_size,
                chunk_overlap = EXCLUDED.chunk_overlap,
                metadata = EXCLUDED.metadata,
                enabled = EXCLUDED.enabled,
                updated_at = NOW()
            RETURNING *
        """

        async with self.pool.acquire() as conn:
            await conn.execute(
                query,
                corpus.corpus_id,
                corpus.corpus_name,
                corpus.display_name,
                corpus.description,
                corpus.vertex_corpus_name,
                corpus.embedding_model,
                corpus.vector_db_type,
                json.dumps(corpus.vector_db_config),
                corpus.document_count,
                corpus.chunk_size,
                corpus.chunk_overlap,
                json.dumps(corpus.metadata),
                corpus.enabled,
            )

        return corpus

    async def delete_corpus(self, corpus_id: str) -> bool:
        """Delete a corpus configuration."""
        query = "DELETE FROM corpuses WHERE corpus_id = $1"

        async with self.pool.acquire() as conn:
            result = await conn.execute(query, corpus_id)
            return result == "DELETE 1"

    async def assign_corpus_to_agent(
        self, agent_id: str, corpus_id: str, priority: int = 1
    ) -> bool:
        """Assign a corpus to an agent."""
        query = """
            INSERT INTO agent_corpuses (agent_id, corpus_id, priority)
            VALUES ($1, $2, $3)
            ON CONFLICT (agent_id, corpus_id) DO UPDATE SET
                priority = EXCLUDED.priority
        """

        async with self.pool.acquire() as conn:
            await conn.execute(query, agent_id, corpus_id, priority)
            return True

    async def unassign_corpus_from_agent(
        self, agent_id: str, corpus_id: str
    ) -> bool:
        """Remove a corpus assignment from an agent."""
        query = "DELETE FROM agent_corpuses WHERE agent_id = $1 AND corpus_id = $2"

        async with self.pool.acquire() as conn:
            result = await conn.execute(query, agent_id, corpus_id)
            return result == "DELETE 1"

    def _row_to_corpus_config(self, row) -> CorpusConfig:
        """Convert a database row to CorpusConfig."""
        vector_db_config = row["vector_db_config"]
        if isinstance(vector_db_config, str):
            vector_db_config = json.loads(vector_db_config)

        metadata = row["metadata"]
        if isinstance(metadata, str):
            metadata = json.loads(metadata)

        return CorpusConfig(
            corpus_id=row["corpus_id"],
            corpus_name=row["corpus_name"],
            display_name=row["display_name"],
            description=row.get("description"),
            vertex_corpus_name=row.get("vertex_corpus_name"),
            embedding_model=row.get("embedding_model", "text-embedding-005"),
            vector_db_type=row.get("vector_db_type", "vertex_rag"),
            vector_db_config=vector_db_config or {},
            document_count=row.get("document_count", 0),
            chunk_size=row.get("chunk_size", 1000),
            chunk_overlap=row.get("chunk_overlap", 200),
            priority=row.get("priority", 1),
            metadata=metadata or {},
            enabled=row.get("enabled", True),
        )
=== ./src/infrastructure/adapters/postgres/postgres_group_mapping_repository.py ===
"""PostgreSQL implementation of GroupMappingRepository."""

from typing import List, Optional
from asyncpg import Pool

from src.domain.ports.group_mapping_repository import GroupMappingRepository
from src.domain.models.azure_ad_models import AzureADGroupMapping


class PostgresGroupMappingRepository(GroupMappingRepository):
    """PostgreSQL adapter for Azure AD group mappings."""

    def __init__(self, pool: Pool):
        """
        Initialize repository.

        Args:
            pool: AsyncPG connection pool
        """
        self.pool = pool

    async def get_all_mappings(self, enabled_only: bool = True) -> List[AzureADGroupMapping]:
        """Get all group mappings."""
        query = """
            SELECT mapping_id, group_name, area_type, weight, description, enabled, created_at, updated_at
            FROM azure_ad_group_mappings
            WHERE enabled = TRUE OR $1 = FALSE
            ORDER BY weight DESC, group_name ASC
        """

        async with self.pool.acquire() as conn:
            rows = await conn.fetch(query, enabled_only)

            return [
                AzureADGroupMapping(
                    mapping_id=row['mapping_id'],
                    group_name=row['group_name'],
                    area_type=row['area_type'],
                    weight=row['weight'],
                    description=row['description'],
                    enabled=row['enabled'],
                    created_at=row['created_at'],
                    updated_at=row['updated_at']
                )
                for row in rows
            ]

    async def get_mapping_by_group_name(self, group_name: str) -> Optional[AzureADGroupMapping]:
        """Get mapping for specific group."""
        query = """
            SELECT mapping_id, group_name, area_type, weight, description, enabled, created_at, updated_at
            FROM azure_ad_group_mappings
            WHERE group_name = $1 AND enabled = TRUE
        """

        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(query, group_name)

            if not row:
                return None

            return AzureADGroupMapping(
                mapping_id=row['mapping_id'],
                group_name=row['group_name'],
                area_type=row['area_type'],
                weight=row['weight'],
                description=row['description'],
                enabled=row['enabled'],
                created_at=row['created_at'],
                updated_at=row['updated_at']
            )

    async def get_mappings_by_group_names(self, group_names: List[str]) -> List[AzureADGroupMapping]:
        """Get mappings for multiple groups."""
        if not group_names:
            return []

        query = """
            SELECT mapping_id, group_name, area_type, weight, description, enabled, created_at, updated_at
            FROM azure_ad_group_mappings
            WHERE group_name = ANY($1) AND enabled = TRUE
            ORDER BY weight DESC, group_name ASC
        """

        async with self.pool.acquire() as conn:
            rows = await conn.fetch(query, group_names)

            return [
                AzureADGroupMapping(
                    mapping_id=row['mapping_id'],
                    group_name=row['group_name'],
                    area_type=row['area_type'],
                    weight=row['weight'],
                    description=row['description'],
                    enabled=row['enabled'],
                    created_at=row['created_at'],
                    updated_at=row['updated_at']
                )
                for row in rows
            ]

    async def create_mapping(
        self,
        group_name: str,
        area_type: str,
        weight: int,
        description: Optional[str] = None,
        enabled: bool = True
    ) -> AzureADGroupMapping:
        """Create new group mapping."""
        query = """
            INSERT INTO azure_ad_group_mappings (group_name, area_type, weight, description, enabled)
            VALUES ($1, $2, $3, $4, $5)
            RETURNING mapping_id, group_name, area_type, weight, description, enabled, created_at, updated_at
        """

        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(query, group_name, area_type, weight, description, enabled)

            return AzureADGroupMapping(
                mapping_id=row['mapping_id'],
                group_name=row['group_name'],
                area_type=row['area_type'],
                weight=row['weight'],
                description=row['description'],
                enabled=row['enabled'],
                created_at=row['created_at'],
                updated_at=row['updated_at']
            )

    async def update_mapping(
        self,
        mapping_id: int,
        area_type: Optional[str] = None,
        weight: Optional[int] = None,
        description: Optional[str] = None,
        enabled: Optional[bool] = None
    ) -> Optional[AzureADGroupMapping]:
        """Update existing mapping."""
        # Build dynamic UPDATE query
        updates = []
        params = []
        param_count = 1

        if area_type is not None:
            updates.append(f"area_type = ${param_count}")
            params.append(area_type)
            param_count += 1

        if weight is not None:
            updates.append(f"weight = ${param_count}")
            params.append(weight)
            param_count += 1

        if description is not None:
            updates.append(f"description = ${param_count}")
            params.append(description)
            param_count += 1

        if enabled is not None:
            updates.append(f"enabled = ${param_count}")
            params.append(enabled)
            param_count += 1

        if not updates:
            # Nothing to update
            return await self.get_mapping_by_id(mapping_id)

        params.append(mapping_id)

        query = f"""
            UPDATE azure_ad_group_mappings
            SET {', '.join(updates)}
            WHERE mapping_id = ${param_count}
            RETURNING mapping_id, group_name, area_type, weight, description, enabled, created_at, updated_at
        """

        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(query, *params)

            if not row:
                return None

            return AzureADGroupMapping(
                mapping_id=row['mapping_id'],
                group_name=row['group_name'],
                area_type=row['area_type'],
                weight=row['weight'],
                description=row['description'],
                enabled=row['enabled'],
                created_at=row['created_at'],
                updated_at=row['updated_at']
            )

    async def delete_mapping(self, mapping_id: int) -> bool:
        """Delete mapping."""
        query = "DELETE FROM azure_ad_group_mappings WHERE mapping_id = $1"

        async with self.pool.acquire() as conn:
            result = await conn.execute(query, mapping_id)
            return result == "DELETE 1"

    async def get_mapping_by_id(self, mapping_id: int) -> Optional[AzureADGroupMapping]:
        """Get mapping by ID."""
        query = """
            SELECT mapping_id, group_name, area_type, weight, description, enabled, created_at, updated_at
            FROM azure_ad_group_mappings
            WHERE mapping_id = $1
        """

        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(query, mapping_id)

            if not row:
                return None

            return AzureADGroupMapping(
                mapping_id=row['mapping_id'],
                group_name=row['group_name'],
                area_type=row['area_type'],
                weight=row['weight'],
                description=row['description'],
                enabled=row['enabled'],
                created_at=row['created_at'],
                updated_at=row['updated_at']
            )
=== ./src/infrastructure/adapters/postgres/sessions_schema.sql ===
-- Sessions and conversation history tables

-- Sessions table for tracking conversations
CREATE TABLE IF NOT EXISTS sessions (
    session_id VARCHAR(255) PRIMARY KEY,
    app_name VARCHAR(255) NOT NULL,
    user_id VARCHAR(255) NOT NULL,
    agent_id VARCHAR(255) REFERENCES agents(agent_id) ON DELETE SET NULL,
    -- Session metadata
    title VARCHAR(500),
    status VARCHAR(50) DEFAULT 'active' CHECK (status IN ('active', 'closed', 'archived')),
    metadata JSONB DEFAULT '{}'::jsonb,
    -- Timestamps
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    last_message_at TIMESTAMP WITH TIME ZONE,
    closed_at TIMESTAMP WITH TIME ZONE
);

-- Messages table for conversation history
CREATE TABLE IF NOT EXISTS messages (
    message_id VARCHAR(255) PRIMARY KEY,
    session_id VARCHAR(255) NOT NULL REFERENCES sessions(session_id) ON DELETE CASCADE,
    -- Message details
    role VARCHAR(50) NOT NULL CHECK (role IN ('user', 'agent', 'system', 'tool')),
    content TEXT NOT NULL,
    -- Tool information (for tool calls/results)
    tool_name VARCHAR(255),
    tool_call_id VARCHAR(255),
    -- Message metadata
    tokens_used INTEGER,
    model_used VARCHAR(100),
    metadata JSONB DEFAULT '{}'::jsonb,
    -- Timestamps
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Indexes for sessions
CREATE INDEX IF NOT EXISTS idx_sessions_user_id ON sessions(user_id);
CREATE INDEX IF NOT EXISTS idx_sessions_agent_id ON sessions(agent_id);
CREATE INDEX IF NOT EXISTS idx_sessions_status ON sessions(status);
CREATE INDEX IF NOT EXISTS idx_sessions_created_at ON sessions(created_at);
CREATE INDEX IF NOT EXISTS idx_sessions_app_name_user ON sessions(app_name, user_id);

-- Indexes for messages
CREATE INDEX IF NOT EXISTS idx_messages_session_id ON messages(session_id);
CREATE INDEX IF NOT EXISTS idx_messages_role ON messages(role);
CREATE INDEX IF NOT EXISTS idx_messages_created_at ON messages(created_at);
CREATE INDEX IF NOT EXISTS idx_messages_session_created ON messages(session_id, created_at);

-- Function to update session's last_message_at timestamp
CREATE OR REPLACE FUNCTION update_session_last_message()
RETURNS TRIGGER AS $$
BEGIN
    UPDATE sessions
    SET last_message_at = NEW.created_at,
        updated_at = NOW()
    WHERE session_id = NEW.session_id;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger to update session timestamp on new message
DROP TRIGGER IF EXISTS trigger_update_session_last_message ON messages;
CREATE TRIGGER trigger_update_session_last_message
    AFTER INSERT ON messages
    FOR EACH ROW
    EXECUTE FUNCTION update_session_last_message();
=== ./src/infrastructure/adapters/postgres/postgres_session_service.py ===
"""PostgreSQL-backed session service for ADK agents."""

import uuid
from datetime import datetime
from typing import Optional, List
from asyncpg import Pool

from google.adk.sessions.session import Session as AdkSession
from google.genai import types

from src.domain.models import Session, Message


class PostgresSessionService:
    """
    PostgreSQL implementation of ADK SessionService.

    This stores conversation sessions and messages in PostgreSQL for:
    - Persistent conversation history
    - Multi-instance support
    - Analytics and monitoring
    - Conversation resumption
    """

    def __init__(self, pool: Pool):
        """
        Initialize with database connection pool.

        Args:
            pool: AsyncPG connection pool
        """
        self.pool = pool

    async def create_session(
        self,
        app_name: str,
        user_id: str,
        session_id: Optional[str] = None,
        agent_id: Optional[str] = None,
        state: Optional[dict] = None,
    ) -> AdkSession:
        """
        Create a new session.

        Args:
            app_name: Application name
            user_id: User identifier
            session_id: Optional session ID (generated if not provided)
            agent_id: Optional agent ID
            state: Optional state dictionary (for ADK compatibility)

        Returns:
            ADK Session object
        """
        if not session_id:
            session_id = f"sess_{uuid.uuid4().hex[:12]}"

        # Store in database
        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO sessions (session_id, app_name, user_id, agent_id, status)
                VALUES ($1, $2, $3, $4, 'active')
                ON CONFLICT (session_id) DO NOTHING
                """,
                session_id, app_name, user_id, agent_id
            )

        # Return ADK Session object
        return AdkSession(
            session_id=session_id,
            app_name=app_name,
            user_id=user_id,
            history=[]
        )

    async def get_session(
        self,
        app_name: str,
        user_id: str,
        session_id: str,
        config: Optional[dict] = None,
    ) -> Optional[AdkSession]:
        """
        Get an existing session with its history.

        Args:
            app_name: Application name
            user_id: User identifier
            session_id: Session identifier
            config: Optional config dictionary (for ADK compatibility)

        Returns:
            ADK Session object with history or None
        """
        async with self.pool.acquire() as conn:
            # Get session
            session_row = await conn.fetchrow(
                """
                SELECT session_id, app_name, user_id, agent_id, status
                FROM sessions
                WHERE session_id = $1 AND app_name = $2 AND user_id = $3
                """,
                session_id, app_name, user_id
            )

            if not session_row:
                return None

            # Get messages
            message_rows = await conn.fetch(
                """
                SELECT role, content, created_at
                FROM messages
                WHERE session_id = $1
                ORDER BY created_at ASC
                """,
                session_id
            )

            # Convert to ADK Content objects
            history = []
            for msg in message_rows:
                history.append(
                    types.Content(
                        role=msg['role'],
                        parts=[types.Part(text=msg['content'])]
                    )
                )

            return AdkSession(
                session_id=session_id,
                app_name=app_name,
                user_id=user_id,
                history=history
            )

    async def list_sessions(
        self,
        app_name: str,
        user_id: str
    ) -> List[AdkSession]:
        """
        List all sessions for a user.

        Args:
            app_name: Application name
            user_id: User identifier

        Returns:
            List of ADK Session objects
        """
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(
                """
                SELECT session_id, app_name, user_id, agent_id
                FROM sessions
                WHERE app_name = $1 AND user_id = $2 AND status = 'active'
                ORDER BY created_at DESC
                """,
                app_name, user_id
            )

            return [
                AdkSession(
                    session_id=row['session_id'],
                    app_name=row['app_name'],
                    user_id=row['user_id'],
                    history=[]
                )
                for row in rows
            ]

    async def delete_session(
        self,
        app_name: str,
        user_id: str,
        session_id: str
    ) -> bool:
        """
        Delete a session (actually marks as closed).

        Args:
            app_name: Application name
            user_id: User identifier
            session_id: Session identifier

        Returns:
            True if deleted, False otherwise
        """
        async with self.pool.acquire() as conn:
            result = await conn.execute(
                """
                UPDATE sessions
                SET status = 'closed', closed_at = NOW()
                WHERE session_id = $1 AND app_name = $2 AND user_id = $3
                """,
                session_id, app_name, user_id
            )
            return result == "UPDATE 1"

    async def save_message(
        self,
        session_id: str,
        role: str,
        content: str,
        tool_name: Optional[str] = None,
        tool_call_id: Optional[str] = None,
        model_used: Optional[str] = None,
        tokens_used: Optional[int] = None
    ) -> str:
        """
        Save a message to the session.

        Args:
            session_id: Session identifier
            role: Message role (user, agent, system, tool)
            content: Message content
            tool_name: Optional tool name
            tool_call_id: Optional tool call ID
            model_used: Optional model identifier
            tokens_used: Optional token count

        Returns:
            Message ID
        """
        message_id = f"msg_{uuid.uuid4().hex[:12]}"

        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO messages (
                    message_id, session_id, role, content,
                    tool_name, tool_call_id, model_used, tokens_used
                )
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
                """,
                message_id, session_id, role, content,
                tool_name, tool_call_id, model_used, tokens_used
            )

        return message_id
=== ./src/infrastructure/adapters/postgres/__init__.py ===
from .postgres_agent_repository import PostgresAgentRepository
from .postgres_corpus_repository import PostgresCorpusRepository
from .postgres_session_service import PostgresSessionService
from .postgres_group_mapping_repository import PostgresGroupMappingRepository

__all__ = [
    "PostgresAgentRepository",
    "PostgresCorpusRepository",
    "PostgresSessionService",
    "PostgresGroupMappingRepository",
]
=== ./src/infrastructure/adapters/__init__.py ===
=== ./src/infrastructure/tools/sample_tools.py ===
"""Sample tool implementations for ADK agents."""

from datetime import datetime
from typing import Any


def search_web(query: str) -> dict[str, Any]:
    """
    Search the web for information.

    Args:
        query: The search query

    Returns:
        A dictionary with search results
    """
    # This is a placeholder implementation
    # In production, you would integrate with a real search API
    return {
        "status": "success",
        "query": query,
        "results": [
            {
                "title": f"Result for: {query}",
                "url": "https://example.com",
                "snippet": f"This is a sample search result for {query}",
            }
        ],
        "timestamp": datetime.now().isoformat(),
    }


def calculate(expression: str) -> dict[str, Any]:
    """
    Perform mathematical calculations.

    Args:
        expression: A mathematical expression to evaluate

    Returns:
        A dictionary with the calculation result
    """
    try:
        # Note: In production, use a safe math parser instead of eval
        # This is just for demonstration purposes
        result = eval(expression, {"__builtins__": {}}, {})
        return {
            "status": "success",
            "expression": expression,
            "result": result,
        }
    except Exception as e:
        return {
            "status": "error",
            "expression": expression,
            "error": str(e),
        }


def get_weather(city: str, country: str = "US") -> dict[str, Any]:
    """
    Get current weather information for a city.

    Args:
        city: The name of the city
        country: The country code (default: US)

    Returns:
        A dictionary with weather information
    """
    # This is a placeholder implementation
    # In production, you would integrate with a real weather API
    return {
        "status": "success",
        "location": f"{city}, {country}",
        "temperature": "72°F",
        "conditions": "Sunny",
        "humidity": "45%",
        "wind_speed": "10 mph",
        "timestamp": datetime.now().isoformat(),
    }


def get_current_time(city: str) -> dict[str, Any]:
    """
    Returns the current time in a specified city.

    Args:
        city: The name of the city

    Returns:
        A dictionary with the current time
    """
    return {
        "status": "success",
        "city": city,
        "time": datetime.now().strftime("%I:%M %p"),
        "timezone": "UTC",
    }
=== ./src/infrastructure/tools/tool_registry.py ===
"""Tool registry for dynamically loading and managing agent tools."""

import importlib
import inspect
from typing import Any, Callable, Optional
from src.domain.models import ToolConfig, CorpusConfig


class ToolRegistry:
    """
    Registry for managing and loading tools dynamically.

    This class handles the mapping between tool configurations stored in
    the database and actual Python functions that can be used by ADK agents.
    """

    def __init__(self):
        """Initialize the tool registry."""
        self._tools: dict[str, Callable] = {}
        self._register_builtin_tools()

    def _register_builtin_tools(self):
        """Register built-in tools."""
        from src.infrastructure.tools import sample_tools

        # Auto-register all functions from sample_tools module
        for name, func in inspect.getmembers(sample_tools, inspect.isfunction):
            if not name.startswith("_"):
                self._tools[name] = func

    def register_tool(self, name: str, func: Callable) -> None:
        """
        Register a new tool function.

        Args:
            name: The name of the tool
            func: The function to register
        """
        if not callable(func):
            raise ValueError(f"Tool {name} must be callable")

        self._tools[name] = func

    def get_tool(self, tool_config: ToolConfig, corpuses: list = None, agent_service: Any = None) -> Optional[Callable]:
        """
        Get a tool function based on its configuration.

        Args:
            tool_config: The tool configuration
            corpuses: List of corpus configurations (for RAG tools)
            agent_service: Agent service instance (for agent tools)

        Returns:
            The tool function if found, None otherwise
        """
        if not tool_config.enabled:
            return None

        if tool_config.tool_type == "function":
            # For function tools, look up by function_name
            function_name = tool_config.function_name or tool_config.tool_name
            return self._tools.get(function_name)

        elif tool_config.tool_type == "builtin":
            # For built-in ADK tools, return the tool name
            # The agent service will handle loading these
            return tool_config.tool_name

        elif tool_config.tool_type == "rag":
            # For RAG tools, create a specialized RAG tool with corpuses
            return self._create_rag_tool(tool_config, corpuses)

        elif tool_config.tool_type == "agent":
            # For agent tools, return a reference that can call another agent
            return self._create_agent_tool(tool_config, agent_service)

        elif tool_config.tool_type == "third_party":
            # For third-party tools, attempt dynamic import
            return self._load_third_party_tool(tool_config)

        return None

    def _create_rag_tool(self, tool_config: ToolConfig, corpuses: list) -> Optional[Callable]:
        """
        Create a RAG tool with bound corpuses.

        Args:
            tool_config: The tool configuration
            corpuses: List of corpus configurations

        Returns:
            A callable RAG tool function
        """
        from src.infrastructure.tools.rag_tool import create_rag_tool

        if not corpuses:
            print(f"Warning: RAG tool {tool_config.tool_name} has no corpuses configured")
            return None

        rag_tool = create_rag_tool(corpuses)
        return rag_tool

    def _create_agent_tool(self, tool_config: ToolConfig, agent_service: Any) -> Optional[Callable]:
        """
        Create an agent tool that delegates to another agent.

        Args:
            tool_config: The tool configuration
            agent_service: The agent service instance

        Returns:
            A callable that invokes another agent
        """
        if not agent_service:
            print(f"Warning: Agent tool {tool_config.tool_name} requires agent_service")
            return None

        # Get the target agent ID from function_name or parameters
        target_agent_id = tool_config.function_name or tool_config.parameters.get("agent_id")

        if not target_agent_id:
            print(f"Warning: Agent tool {tool_config.tool_name} has no target agent_id")
            return None

        # Create a function that delegates to the target agent
        async def delegate_to_agent(prompt: str, **kwargs) -> dict[str, Any]:
            """Delegate task to another agent."""
            try:
                response = await agent_service.invoke_agent(target_agent_id, prompt, **kwargs)
                return {
                    "status": "success",
                    "agent_id": target_agent_id,
                    "response": response
                }
            except Exception as e:
                return {
                    "status": "error",
                    "agent_id": target_agent_id,
                    "error": str(e)
                }

        return delegate_to_agent

    def _load_third_party_tool(self, tool_config: ToolConfig) -> Optional[Callable]:
        """
        Dynamically load a third-party tool.

        Args:
            tool_config: The tool configuration

        Returns:
            The loaded tool function or None
        """
        try:
            # Expect parameters to have 'module' and optionally 'attribute'
            module_name = tool_config.parameters.get("module")
            attr_name = tool_config.parameters.get("attribute", tool_config.function_name)

            if not module_name:
                return None

            module = importlib.import_module(module_name)

            if attr_name:
                return getattr(module, attr_name)
            return module

        except (ImportError, AttributeError) as e:
            print(f"Error loading third-party tool {tool_config.tool_name}: {e}")
            return None

    def list_tools(self) -> list[str]:
        """
        List all registered tool names.

        Returns:
            List of tool names
        """
        return list(self._tools.keys())

    def get_tools_for_configs(
        self,
        tool_configs: list[ToolConfig],
        corpuses: list[CorpusConfig] = None,
        agent_service: Any = None
    ) -> list[Any]:
        """
        Get all tool functions for a list of tool configurations.

        Args:
            tool_configs: List of tool configurations
            corpuses: List of corpus configurations (for RAG tools)
            agent_service: Agent service instance (for agent tools)

        Returns:
            List of tool functions (excluding None values)
        """
        tools = []
        for config in tool_configs:
            tool = self.get_tool(config, corpuses=corpuses, agent_service=agent_service)
            if tool is not None:
                tools.append(tool)
        return tools
=== ./src/infrastructure/tools/rag_tool.py ===
"""RAG (Retrieval-Augmented Generation) tool using Vertex AI RAG Engine."""

import os
from typing import Any, Optional
import vertexai
from vertexai import rag
from src.domain.models import CorpusConfig


class VertexRAGTool:
    """
    Vertex AI RAG Engine tool for retrieving information from corpuses.

    This tool uses Google's Vertex AI RAG Engine to perform semantic search
    across configured corpuses and retrieve relevant context for the LLM.
    """

    def __init__(self, corpuses: list[CorpusConfig]):
        """
        Initialize the RAG tool with corpuses.

        Args:
            corpuses: List of corpus configurations to search
        """
        self.corpuses = corpuses
        self.project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
        self.location = os.getenv("GOOGLE_CLOUD_REGION", "us-central1")

        # Initialize Vertex AI
        if self.project_id:
            vertexai.init(project=self.project_id, location=self.location)

    def __call__(self, query: str, top_k: int = 5, similarity_threshold: float = 0.5) -> dict[str, Any]:
        """
        Search across all configured corpuses for relevant information.

        Args:
            query: The search query
            top_k: Number of top results to return per corpus
            similarity_threshold: Minimum similarity score (0.0 to 1.0)

        Returns:
            Dictionary with search results from all corpuses
        """
        if not self.corpuses:
            return {
                "status": "error",
                "message": "No corpuses configured for this agent",
                "results": []
            }

        if not self.project_id:
            return {
                "status": "error",
                "message": "GOOGLE_CLOUD_PROJECT environment variable not set",
                "results": []
            }

        all_results = []

        for corpus in self.corpuses:
            if not corpus.enabled or not corpus.vertex_corpus_name:
                continue

            try:
                # Query the corpus using Vertex AI RAG Engine
                results = self._query_corpus(
                    corpus=corpus,
                    query=query,
                    top_k=top_k,
                    similarity_threshold=similarity_threshold
                )

                all_results.extend(results)

            except Exception as e:
                print(f"Error querying corpus {corpus.corpus_name}: {e}")
                all_results.append({
                    "corpus_id": corpus.corpus_id,
                    "corpus_name": corpus.corpus_name,
                    "error": str(e),
                    "status": "error"
                })

        # Sort by relevance score (if available) and priority
        all_results.sort(
            key=lambda x: (
                -x.get("relevance_score", 0.0),
                x.get("priority", 999)
            )
        )

        return {
            "status": "success",
            "query": query,
            "total_results": len(all_results),
            "corpuses_searched": len(self.corpuses),
            "results": all_results[:top_k * 2]  # Return up to 2x top_k results
        }

    def _query_corpus(
        self,
        corpus: CorpusConfig,
        query: str,
        top_k: int,
        similarity_threshold: float
    ) -> list[dict[str, Any]]:
        """
        Query a single corpus using Vertex AI RAG Engine.

        Args:
            corpus: The corpus configuration
            query: The search query
            top_k: Number of results to return
            similarity_threshold: Minimum similarity score

        Returns:
            List of search results
        """
        results = []

        try:
            if corpus.vector_db_type == "vertex_rag":
                # Use Vertex AI RAG Engine
                response = rag.retrieval_query(
                    rag_resources=[
                        rag.RagResource(
                            rag_corpus=corpus.vertex_corpus_name,
                        )
                    ],
                    text=query,
                    similarity_top_k=top_k,
                    vector_distance_threshold=1.0 - similarity_threshold,
                )

                # Process response
                if hasattr(response, 'contexts') and response.contexts:
                    for idx, context in enumerate(response.contexts.contexts):
                        results.append({
                            "corpus_id": corpus.corpus_id,
                            "corpus_name": corpus.corpus_name,
                            "priority": corpus.priority,
                            "rank": idx + 1,
                            "text": context.text if hasattr(context, 'text') else str(context),
                            "relevance_score": context.score if hasattr(context, 'score') else None,
                            "source": context.source_uri if hasattr(context, 'source_uri') else None,
                        })

            else:
                # For other vector DB types, return a placeholder
                results.append({
                    "corpus_id": corpus.corpus_id,
                    "corpus_name": corpus.corpus_name,
                    "priority": corpus.priority,
                    "text": f"RAG support for {corpus.vector_db_type} not yet implemented",
                    "status": "not_implemented"
                })

        except Exception as e:
            results.append({
                "corpus_id": corpus.corpus_id,
                "corpus_name": corpus.corpus_name,
                "error": str(e),
                "status": "error"
            })

        return results


def create_rag_tool(corpuses: list[CorpusConfig]) -> VertexRAGTool:
    """
    Factory function to create a RAG tool.

    Args:
        corpuses: List of corpus configurations

    Returns:
        Configured VertexRAGTool instance
    """
    return VertexRAGTool(corpuses)


# Simple function wrapper for ADK compatibility
def vertex_rag_retrieval(query: str, corpuses: list = None, top_k: int = 5) -> dict[str, Any]:
    """
    Retrieve information from RAG corpuses.

    This function is designed to be registered as a tool in the ADK agent.
    Note: The corpuses parameter should be injected by the tool registry.

    Args:
        query: The search query
        corpuses: List of corpus configurations (injected)
        top_k: Number of results to return

    Returns:
        Dictionary with search results
    """
    if not corpuses:
        return {
            "status": "error",
            "message": "No corpuses configured",
            "results": []
        }

    tool = VertexRAGTool(corpuses)
    return tool(query, top_k=top_k)
=== ./src/infrastructure/tools/__init__.py ===
from .tool_registry import ToolRegistry
from .sample_tools import search_web, calculate, get_weather

__all__ = ["ToolRegistry", "search_web", "calculate", "get_weather"]
=== ./src/infrastructure/__init__.py ===
=== ./src/services/azure_ad_router.py ===
"""
Azure AD Group to Agent Router Service.

This service maps Azure AD groups to agent area_types for automatic routing.
Mappings are stored in database with configurable weights.
"""
from typing import Optional, Dict, List
import logging

from src.domain.ports.group_mapping_repository import GroupMappingRepository

logger = logging.getLogger(__name__)


class AzureADGroupMapper:
    """Maps Azure AD groups to agent area types using database-stored mappings."""

    def __init__(self, group_mapping_repository: GroupMappingRepository):
        """
        Initialize group mapper.

        Args:
            group_mapping_repository: Repository for group mappings
        """
        self.repository = group_mapping_repository

    async def get_area_type_from_groups(self, user_groups: List[str]) -> str:
        """
        Get the appropriate area_type based on user's Azure AD groups.

        Uses weight-based selection: if user is in multiple groups,
        the group with the highest weight determines the area_type.

        Args:
            user_groups: List of Azure AD group names the user belongs to

        Returns:
            area_type to use for agent selection (defaults to 'general')
        """
        if not user_groups:
            logger.info("No user groups found, defaulting to 'general'")
            return 'general'

        try:
            # Get mappings for all user's groups from database
            mappings = await self.repository.get_mappings_by_group_names(user_groups)

            if not mappings:
                logger.info(f"No mappings found for groups {user_groups}, defaulting to 'general'")
                return 'general'

            # Sort by weight (descending) - highest weight wins
            # Already sorted by repository, but let's be explicit
            sorted_mappings = sorted(mappings, key=lambda m: m.weight, reverse=True)

            # Use the highest weight mapping
            highest_priority = sorted_mappings[0]

            logger.info(
                f"User in {len(user_groups)} group(s). "
                f"Selected '{highest_priority.group_name}' (weight={highest_priority.weight}) "
                f"-> area_type '{highest_priority.area_type}'"
            )

            return highest_priority.area_type

        except Exception as e:
            logger.error(f"Error getting area_type from groups: {e}")
            return 'general'

    async def get_all_area_types_for_user(self, user_groups: List[str]) -> List[Dict[str, any]]:
        """
        Get all possible area_types for a user based on their groups.
        Includes weight information for transparency.

        Args:
            user_groups: List of Azure AD group names

        Returns:
            List of dicts with area_type, weight, and group_name
        """
        if not user_groups:
            return [{'area_type': 'general', 'weight': 0, 'group_name': 'default'}]

        try:
            mappings = await self.repository.get_mappings_by_group_names(user_groups)

            result = [
                {
                    'area_type': m.area_type,
                    'weight': m.weight,
                    'group_name': m.group_name,
                    'description': m.description
                }
                for m in mappings
            ]

            # Sort by weight descending
            result.sort(key=lambda x: x['weight'], reverse=True)

            # Always include 'general' as fallback if not already present
            if not any(r['area_type'] == 'general' for r in result):
                result.append({
                    'area_type': 'general',
                    'weight': 0,
                    'group_name': 'fallback',
                    'description': 'General fallback agent'
                })

            return result

        except Exception as e:
            logger.error(f"Error getting all area_types: {e}")
            return [{'area_type': 'general', 'weight': 0, 'group_name': 'error'}]

    async def can_access_area(self, user_groups: List[str], area_type: str) -> bool:
        """
        Check if user can access a specific area based on their groups.

        Args:
            user_groups: List of Azure AD group names
            area_type: area_type to check access for

        Returns:
            True if user has access, False otherwise
        """
        user_areas = await self.get_all_area_types_for_user(user_groups)
        accessible_areas = [a['area_type'] for a in user_areas]

        # Admin area grants access to everything
        if 'admin' in accessible_areas:
            return True

        return area_type in accessible_areas


class AgentRouter:
    """Routes user messages to appropriate agents based on Azure AD groups."""

    def __init__(self, agent_repository, group_mapping_repository: GroupMappingRepository):
        """
        Initialize agent router.

        Args:
            agent_repository: Repository for accessing agents
            group_mapping_repository: Repository for group mappings
        """
        self.agent_repository = agent_repository
        self.group_mapper = AzureADGroupMapper(group_mapping_repository)

    async def get_agent_for_user(self, user_groups: List[str]) -> Optional[Dict]:
        """
        Get the appropriate agent for a user based on their Azure AD groups.

        Uses weight-based selection for users in multiple groups.

        Args:
            user_groups: List of Azure AD group names

        Returns:
            Agent configuration or None
        """
        # Get area_type from user's groups (weight-based selection)
        area_type = await self.group_mapper.get_area_type_from_groups(user_groups)

        logger.info(f"Looking for agent with area_type='{area_type}'")

        # Query database for agent with matching area_type
        agents = await self.agent_repository.list_agents(enabled_only=True)

        # Find agent matching the area_type
        for agent in agents:
            if agent.area_type == area_type:
                logger.info(f"Found agent: {agent.name} (area_type={agent.area_type})")
                return agent

        # Fallback to general agent if no specific match
        logger.warning(f"No agent found for area_type='{area_type}', looking for 'general'")
        for agent in agents:
            if agent.area_type == 'general':
                logger.info(f"Using fallback agent: {agent.name}")
                return agent

        logger.error("No suitable agent found (not even 'general')")
        return None

    async def get_available_agents_for_user(self, user_groups: List[str]) -> List[Dict]:
        """
        Get all agents the user can access based on their groups.
        Sorted by weight (priority).

        Args:
            user_groups: List of Azure AD group names

        Returns:
            List of accessible agents with their weights
        """
        # Get all area_types user can access (with weights)
        area_info = await self.group_mapper.get_all_area_types_for_user(user_groups)

        logger.info(f"User can access {len(area_info)} area_types")

        # Query database for matching agents
        agents = await self.agent_repository.list_agents(enabled_only=True)

        # Build result with weight information
        accessible_agents = []
        for info in area_info:
            area_type = info['area_type']
            for agent in agents:
                if agent.area_type == area_type:
                    accessible_agents.append({
                        'agent': agent,
                        'weight': info['weight'],
                        'group_name': info['group_name'],
                        'group_description': info.get('description')
                    })
                    break

        # Sort by weight descending
        accessible_agents.sort(key=lambda x: x['weight'], reverse=True)

        logger.info(f"Found {len(accessible_agents)} accessible agents")
        return accessible_agents
=== ./src/services/teams_integration.py ===
"""
Teams Integration Service.

Handles integration between Microsoft Teams bot and GCP agents.
Routes messages based on Azure AD group membership.
"""
import os
import logging
from typing import Optional, List, Dict
from msgraph import GraphServiceClient
from azure.identity import ClientSecretCredential

from src.services.azure_ad_router import AgentRouter, AzureADGroupMapper
from src.domain.services.agent_service import AgentService
from src.domain.ports.group_mapping_repository import GroupMappingRepository

logger = logging.getLogger(__name__)


class TeamsAgentIntegration:
    """
    Integration service for Microsoft Teams bot with GCP agents.

    This service:
    1. Receives message from Teams user
    2. Gets user's Azure AD groups via Microsoft Graph
    3. Maps groups to agent area_type
    4. Routes message to appropriate GCP agent
    5. Returns agent response to Teams
    """

    def __init__(
        self,
        agent_service: AgentService,
        group_mapping_repository: GroupMappingRepository,
        graph_tenant_id: Optional[str] = None,
        graph_client_id: Optional[str] = None,
        graph_client_secret: Optional[str] = None
    ):
        """
        Initialize Teams integration service.

        Args:
            agent_service: GCP agent service instance
            group_mapping_repository: Repository for Azure AD group mappings
            graph_tenant_id: Azure AD tenant ID
            graph_client_id: App client ID
            graph_client_secret: App client secret
        """
        self.agent_service = agent_service
        self.agent_router = AgentRouter(agent_service.repository, group_mapping_repository)

        # Initialize Microsoft Graph client
        tenant_id = graph_tenant_id or os.getenv('GRAPH_TENANT_ID')
        client_id = graph_client_id or os.getenv('GRAPH_CLIENT_ID')
        client_secret = graph_client_secret or os.getenv('GRAPH_CLIENT_SECRET')

        if tenant_id and client_id and client_secret:
            credential = ClientSecretCredential(
                tenant_id=tenant_id,
                client_id=client_id,
                client_secret=client_secret
            )
            self.graph_client = GraphServiceClient(
                credentials=credential,
                scopes=['https://graph.microsoft.com/.default']
            )
        else:
            logger.warning("Microsoft Graph credentials not configured")
            self.graph_client = None

    async def get_user_groups(self, aad_user_id: str) -> List[str]:
        """
        Get user's Azure AD group memberships.

        Args:
            aad_user_id: Azure AD user object ID

        Returns:
            List of group display names
        """
        if not self.graph_client:
            logger.error("Graph client not initialized")
            return []

        try:
            # Get user's transitive group memberships
            result = await self.graph_client.users.by_user_id(aad_user_id).transitive_member_of.get()

            if not result or not result.value:
                logger.info(f"No groups found for user {aad_user_id}")
                return []

            # Extract group display names
            group_names = [
                item.display_name for item in result.value
                if hasattr(item, 'display_name') and item.odata_type == '#microsoft.graph.group'
            ]

            logger.info(f"User {aad_user_id} groups: {group_names}")
            return group_names

        except Exception as e:
            logger.error(f"Error getting user groups: {e}")
            return []

    async def process_message(
        self,
        user_message: str,
        aad_user_id: str,
        user_name: str,
        session_id: Optional[str] = None,
        persist_session: bool = False
    ) -> Dict[str, any]:
        """
        Process a message from Teams user.

        Args:
            user_message: Message text from user
            aad_user_id: Azure AD user object ID
            user_name: User's display name
            session_id: Optional session ID for conversation continuity
            persist_session: Whether to persist session in database

        Returns:
            Dictionary with response and metadata
        """
        try:
            # Step 1: Get user's Azure AD groups
            user_groups = await self.get_user_groups(aad_user_id)

            if not user_groups:
                logger.warning(f"No groups found for user {user_name}, using general agent")
                user_groups = ['General-Users']  # Fallback

            # Step 2: Route to appropriate agent based on groups
            agent_config = await self.agent_router.get_agent_for_user(user_groups)

            if not agent_config:
                return {
                    'success': False,
                    'error': 'No suitable agent found',
                    'response': 'Sorry, I cannot process your request at this time.'
                }

            logger.info(f"Routing user '{user_name}' to agent '{agent_config.name}' (area: {agent_config.area_type})")

            # Step 3: Invoke the appropriate GCP agent
            response = await self.agent_service.invoke_agent(
                agent_id=agent_config.agent_id,
                prompt=user_message,
                user_id=aad_user_id,
                session_id=session_id,
                persist_session=persist_session
            )

            # Step 4: Return response with metadata
            return {
                'success': True,
                'response': response,
                'agent_name': agent_config.name,
                'agent_area': agent_config.area_type,
                'user_groups': user_groups,
                'session_id': session_id
            }

        except Exception as e:
            logger.error(f"Error processing message: {e}", exc_info=True)
            return {
                'success': False,
                'error': str(e),
                'response': 'Sorry, an error occurred while processing your message.'
            }

    async def get_user_agent_info(self, aad_user_id: str) -> Dict:
        """
        Get information about which agent(s) a user can access.

        Args:
            aad_user_id: Azure AD user object ID

        Returns:
            Dictionary with agent information
        """
        try:
            # Get user's groups
            user_groups = await self.get_user_groups(aad_user_id)

            # Get primary agent
            primary_agent = await self.agent_router.get_agent_for_user(user_groups)

            # Get all accessible agents
            accessible_agents = await self.agent_router.get_available_agents_for_user(user_groups)

            return {
                'user_groups': user_groups,
                'primary_agent': {
                    'name': primary_agent.name,
                    'description': primary_agent.description,
                    'area': primary_agent.area_type
                } if primary_agent else None,
                'accessible_agents': [
                    {
                        'name': agent.name,
                        'description': agent.description,
                        'area': agent.area_type
                    }
                    for agent in accessible_agents
                ]
            }

        except Exception as e:
            logger.error(f"Error getting user agent info: {e}")
            return {'error': str(e)}
=== ./src/main.py ===
"""Main application entry point for Cloud Run."""

import os
import logging
from contextlib import asynccontextmanager

# Configure Vertex AI environment variables BEFORE any ADK imports
# ADK reads these variables during initialization, so they must be set first
if not os.getenv("GOOGLE_GENAI_USE_VERTEXAI"):
    os.environ["GOOGLE_GENAI_USE_VERTEXAI"] = "TRUE"

# Set project and location from Cloud Run's environment
# These are typically already set in Cloud Run, but we ensure they exist
if not os.getenv("GOOGLE_CLOUD_PROJECT"):
    logger_msg = "WARNING: GOOGLE_CLOUD_PROJECT not set. ADK agents will fail."
    print(logger_msg)

if not os.getenv("GOOGLE_CLOUD_LOCATION"):
    # Default to us-central1 if not specified
    os.environ["GOOGLE_CLOUD_LOCATION"] = "us-central1"
    print(f"INFO: GOOGLE_CLOUD_LOCATION not set, defaulting to us-central1")

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from src.application.api import router
from src.application.api.teams_routes import router as teams_router
from src.application.api.group_mapping_routes import router as group_mapping_router
from src.application.di import get_container, close_container


# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Application lifespan manager.

    Handles startup and shutdown events.
    """
    # Startup
    logger.info("Starting application...")
    try:
        container = get_container()
        await container.init_repository()
        logger.info("Application started successfully")
    except Exception as e:
        logger.error(f"Error during startup: {e}")
        raise

    yield

    # Shutdown
    logger.info("Shutting down application...")
    try:
        await close_container()
        logger.info("Application shut down successfully")
    except Exception as e:
        logger.error(f"Error during shutdown: {e}")


# Create FastAPI application
app = FastAPI(
    title="ADK Agent Service",
    description="Google ADK Agent Service with PostgreSQL configuration",
    version="1.0.0",
    lifespan=lifespan,
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include API routes
app.include_router(router, prefix="/api/v1")
app.include_router(teams_router, prefix="/api/v1", tags=["teams"])
app.include_router(group_mapping_router, prefix="/api/v1", tags=["group-mappings"])


@app.get("/")
async def root():
    """Root endpoint."""
    return {
        "message": "ADK Agent Service",
        "version": "1.0.0",
        "docs": "/docs",
    }


if __name__ == "__main__":
    import uvicorn

    port = int(os.getenv("PORT", "8080"))
    host = os.getenv("HOST", "0.0.0.0")

    logger.info(f"Starting server on {host}:{port}")

    uvicorn.run(
        "src.main:app",
        host=host,
        port=port,
        reload=os.getenv("ENVIRONMENT") == "development",
        log_level="info",
    )
=== ./src/__init__.py ===
"""ADK Agent Service with PostgreSQL configuration."""

__version__ = "1.0.0"
